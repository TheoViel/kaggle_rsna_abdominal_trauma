{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.cuda.get_device_name(0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from data.preparation import *\n",
    "from util.metrics import compute_metrics\n",
    "from inference.det import *\n",
    "from util.wbf import fusion, iou\n",
    "from util.boxes import Boxes, expand_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patient, df_img = prepare_data(DATA_PATH)\n",
    "\n",
    "# df = pd.read_csv('../input/active_extravasation_bounding_boxes.csv')\n",
    "# df = df.rename(columns={\"pid\": \"patient_id\", \"series_id\": \"series\", \"instance_number\": \"instance\"})\n",
    "# df = df.merge(df_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "\n",
    "# for i in range(1, 5):\n",
    "#     plt.subplot(1, 4, i)\n",
    "\n",
    "#     idx = np.random.choice(len(df))\n",
    "#     img = cv2.imread(df['path'].values[idx])\n",
    "#     boxes = df[[\"x1\", \"y1\", \"x2\", \"y2\"]].values[idx]\n",
    "\n",
    "#     plot_boxes(img, boxes, bbox_format=\"pascal_voc\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "    fold = 1\n",
    "#     fold = \"fullfit\"\n",
    "    version = \"v2\"\n",
    "    exp = 2\n",
    "    \n",
    "    if fold != \"fullfit\":\n",
    "        name = f\"rsna_{version}_fold{fold}_{exp}\"\n",
    "    else:\n",
    "        name = f\"rsna_{version}_fullfit_{exp}\"\n",
    "\n",
    "    data_dir = f\"../input/yolo/v1/{fold}_train/\"\n",
    "    cfg = f\"../yolox/exps/{name}.py\"\n",
    "#     ckpt = f\"../yolox/YOLOX_outputs/{name}/best_ckpt.pth\"\n",
    "    ckpt = f\"../yolox/YOLOX_outputs/{name}/last_epoch_ckpt.pth\"\n",
    "#     ckpt = f\"../yolox/YOLOX_outputs/{name}/epoch_5_ckpt.pth\"\n",
    "    labels = [\"extravasation\"]\n",
    "\n",
    "    size = (384, 384)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = 0.1\n",
    "    iou_thresh = 0.5\n",
    "    max_per_img = 1\n",
    "\n",
    "    num_workers = 8\n",
    "    val_bs = 64\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marker = retrieve_yolox_model(Config.cfg, Config.ckpt, size=Config.size)\n",
    "model_marker = YoloXWrapper(model_marker, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"path\": glob.glob(Config.data_dir + \"images/valid/*\")})\n",
    "df['gt_path'] = df['path'].apply(lambda x: re.sub(\"images\", \"labels\", x))\n",
    "df['gt_path'] = df['gt_path'].apply(lambda x: re.sub(\".png\", \".txt\", x))\n",
    "\n",
    "df['patient_id'] = df['path'].apply(lambda x: x.split('/')[-1].split('_')[0])\n",
    "df['series'] = df['path'].apply(lambda x: x.split('_')[-2])\n",
    "df['frame'] = df['path'].apply(lambda x: x.split('_')[-1][:-4])\n",
    "\n",
    "df = df.sort_values(['patient_id', 'series', 'frame'], ignore_index=True)\n",
    "# df = df.head(100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- Predict')\n",
    "transforms = get_transfos(size=Config.size)\n",
    "dataset = InferenceDataset(df, transforms)\n",
    "meter = predict(model_marker, dataset, Config, disable_tqdm=False)\n",
    "\n",
    "print('\\n- Update shapes')\n",
    "dataset = InferenceDataset(df, None)\n",
    "for i in range(len(dataset)):\n",
    "    shape = dataset[i][2]\n",
    "    meter.preds[i].update_shape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- Evaluate')\n",
    "\n",
    "recalls = {}\n",
    "for idx in range(len(dataset)):\n",
    "    img, gt, shape = dataset[idx] \n",
    "\n",
    "    gt = Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\")\n",
    "\n",
    "    pred = Boxes(meter.preds[idx]['pascal_voc'][meter.labels[idx] == 0], (shape[0], shape[1]), bbox_format=\"pascal_voc\")\n",
    "    scores = meter.confidences[idx][meter.labels[idx] == 0]\n",
    "\n",
    "    for r in [1, 3, 5]:\n",
    "        metrics = compute_metrics(pred['pascal_voc'][:r], gt['pascal_voc'])\n",
    "        try:\n",
    "            recalls[Config.labels[0] + f\"@{r}\"].append(metrics['recall'])\n",
    "        except:\n",
    "            recalls[Config.labels[0] + f\"@{r}\"] = [metrics['recall']]\n",
    "\n",
    "    if PLOT or not (idx % 500):\n",
    "#     if metrics['recall'] == 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_boxes(img, gt['pascal_voc'], \"pascal_voc\")\n",
    "        plt.title(f'{idx} - Truth - {df.patient_id[idx], df.series[idx], df.frame[idx]}')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_boxes(img, pred['pascal_voc'], \"pascal_voc\")\n",
    "        plt.title(f'Pred - conf={scores[0]:.3f}')\n",
    "        plt.show()\n",
    "        \n",
    "#     if df.patient_id[idx] != \"10217\":\n",
    "#         break\n",
    "#     if PLOT and idx > 20:\n",
    "#         break\n",
    "\n",
    "print('\\n')\n",
    "for k, v in recalls.items():\n",
    "    print(f'Recall {k}: {np.mean(recalls[k]):.3f}')\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion & Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_imgs(img_paths, max_len=600, margin=10):\n",
    "    n_imgs = len(img_paths)\n",
    "    \n",
    "    if n_imgs > 400:\n",
    "        img_paths = img_paths[n_imgs // 6 - margin:]\n",
    "    else:\n",
    "        img_paths = img_paths[max(n_imgs // 8 - margin, 0):]\n",
    "            \n",
    "    img_paths = img_paths[- max_len - margin :]\n",
    "    \n",
    "    return img_paths, n_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)\n",
    "\n",
    "if \"fold\" not in df_patient.columns:\n",
    "    folds = pd.read_csv(DATA_PATH + \"folds_4.csv\")\n",
    "    df_img = df_img.merge(folds)\n",
    "    df_patient = df_patient.merge(folds)\n",
    "    \n",
    "df_img = df_img[[\"patient_id\", \"series\", \"instance\", \"frame\", \"path\", \"extravasation_injury\", \"fold\"]]\n",
    "\n",
    "df_img = df_img[df_img[\"fold\"] == Config.fold]\n",
    "df_img['pred_extravasation'] = (\n",
    "    0.5 * np.load(f\"../logs/2023-09-20/36_r/pred_val_{Config.fold}.npy\")[:, 1] +  0.5 * \n",
    "    np.load(f\"../logs/2023-10-05/13/pred_val_{Config.fold}.npy\")[:, 1]\n",
    ")\n",
    "\n",
    "df_img_max = df_img[['patient_id', 'series', 'extravasation_injury', 'pred_extravasation']].groupby(['patient_id', 'series']).max().reset_index()\n",
    "df_img = df_img.merge(df_img_max, on=['patient_id', 'series'], suffixes=(\"\", \"_agg\"))\n",
    "\n",
    "df_img_cum = df_img.copy()\n",
    "df_img_cum['pred_extravasation'] = (df_img_cum['pred_extravasation'] > 0.2).astype(int)\n",
    "df_img_cum = df_img_cum[['patient_id', 'series', 'extravasation_injury', 'pred_extravasation']].groupby(['patient_id', 'series']).sum().reset_index()\n",
    "df_img = df_img.merge(df_img_cum, on=['patient_id', 'series'], suffixes=(\"\", \"_cum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_f = df_img[(df_img['pred_extravasation_agg'] > 0.2) & (df_img['pred_extravasation_cum'] > 3)]\n",
    "len(df_img_f[df_img_f['extravasation_injury'] == 1].series.unique()), len(df_img_f.series.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['patient_id', 'series', \"frame\"]] = df[['patient_id', 'series', \"frame\"]].astype(int)\n",
    "df_img = df_img.merge(df, on=['patient_id', 'series', \"frame\"], how=\"left\", suffixes=('', '_yolo'))\n",
    "\n",
    "# df_img.dropna(inplace=True)\n",
    "df_img['gt_path'].fillna('', inplace=True)\n",
    "\n",
    "df_img = df_img.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_g = df_img_f[[\"series\", \"extravasation_injury\", \"pred_extravasation\"]].groupby('series').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds, preds_aux = k_fold(Config, df_patient, df_img, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_img_g['extravasation_injury'], df_img_g['pred_extravasation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = [\n",
    "# #     48517, 17447,\n",
    "#     3750, 24136, 39205, 29661, 53257, 3532\n",
    "# ]  # No crop\n",
    "# errors_idk = [4654, 14668, 20619, 60792, 16080, 54917, 16080, 27089, 58540, 15610, 15909, 12151]  # Wrong crop\n",
    "\n",
    "# # removed = [29661, 53257, 63618, 20619, 60961, 63205, 48977, 58540, 48517, 41840]\n",
    "# # removed = [29661, 53257, 63618, 20619, 60961, 63205, 48977, 58540, 48517, 41840]\n",
    "\n",
    "# removed = [24136, 39205, 29661, 5104, 58540, 39222, 48517, 15610, 15786, 41840]\n",
    "# [True, False, False, False, True, False, True, False, True, False]\n",
    "# # [True, False, False, False, False, False, False, True, False, False]\n",
    "\n",
    "# # [True, False, False, False, False, False, False, True, False, False]\n",
    "# # [29661, 53257, 63618, 20619, 60961, 63205, 48977, 58540, 48517, 41840]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "was_hit = np.copy(np.array(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 96\n",
    "\n",
    "PLOT = False\n",
    "\n",
    "SAVE_FOLDER = \"../input/crops_extrav/\"\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "SAVE = True\n",
    "\n",
    "TH_HITS = 0.2\n",
    "MIN_HITS = 3\n",
    "MIN_PRED = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(crops[:, :, :, 0] == crops[:, :, :, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = []\n",
    "ct = -1\n",
    "paths, labels = [], []\n",
    "for study_idx, ((patient_id, series), dfg) in tqdm(enumerate(df_img.groupby(['patient_id', 'series'])), total=len(df_img['series'].unique())):\n",
    "#     if patient_id != 386:\n",
    "#         continue\n",
    "#     if series not in errors + errors_idk:\n",
    "#         continue\n",
    "#     if series != 24136:\n",
    "#         continue\n",
    "\n",
    "    dfg = dfg.reset_index(drop=True)\n",
    "    has_extrav_ = dfg.extravasation_injury.max()\n",
    "\n",
    "    dfg = dfg.iloc[restrict_imgs(np.arange(len(dfg)))[0]].reset_index(drop=True)\n",
    "    has_extrav = dfg.extravasation_injury.max()\n",
    "\n",
    "#     if not has_extrav:\n",
    "#         continue\n",
    "        \n",
    "    print(f'\\n- {patient_id, series} - Has extrav : {has_extrav}')\n",
    "\n",
    "    if has_extrav_ and not has_extrav:\n",
    "        print('Warning, removed extrav when restricting')\n",
    "        \n",
    "    if dfg['pred_extravasation'].max() < MIN_PRED:\n",
    "        if not has_extrav:\n",
    "            print('- Skip low conf')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'- Warning, MIN_PRED={MIN_PRED} would skip extrav as maximum conf is {dfg.pred_extravasation.max()}')\n",
    "\n",
    "    if (dfg['pred_extravasation'] > TH_HITS).sum() < MIN_HITS:\n",
    "        if not has_extrav:\n",
    "            print('- Skip low hits')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'- Warning, MIN_HITS={MIN_HITS} would skip extrav as hits@{TH_HITS} is {(dfg.pred_extravasation > TH_HITS).sum()}', end=\"\")\n",
    "            print(f'\\t hits@{TH_HITS / 2} is {(dfg.pred_extravasation > TH_HITS / 2).sum()}')\n",
    "        \n",
    "    # Truncate to high score area\n",
    "    prev = len(dfg)\n",
    "    start_frame = np.argmax(dfg['pred_extravasation'].values > 0.05)\n",
    "    start_frame = max(0, start_frame - 5)\n",
    "    end_frame = len(dfg) - np.argmax(dfg['pred_extravasation'].values[::-1] > 0.05)\n",
    "    end_frame = min(len(dfg), end_frame + 5)\n",
    "    \n",
    "    if has_extrav and not dfg.iloc[np.arange(start_frame, end_frame)].extravasation_injury.max():  # Lower threshold\n",
    "        print('- Use th=0.01 to remove frames')\n",
    "        start_frame = np.argmax(dfg['pred_extravasation'].values > 0.01)\n",
    "        start_frame = max(0, start_frame - 5)\n",
    "        end_frame = len(dfg) - np.argmax(dfg['pred_extravasation'].values[::-1] > 0.01)\n",
    "        end_frame = min(len(dfg), end_frame + 5)\n",
    "\n",
    "    dfg = dfg.iloc[np.arange(start_frame, end_frame)].reset_index(drop=True)\n",
    "\n",
    "    has_extrav_ = dfg.extravasation_injury.max()\n",
    "    if has_extrav and not has_extrav_:\n",
    "        print('- Warning, removed extrav when truncating frames. Skipping.')\n",
    "        continue\n",
    "\n",
    "    \n",
    "    print(f'- Use {len(dfg)} frames out of {prev}')\n",
    "    \n",
    "#     ct += 1\n",
    "#     if was_hit[ct]:\n",
    "#         continue\n",
    "    \n",
    "    # Inference\n",
    "    transforms = get_transfos(size=Config.size)\n",
    "    dataset = InferenceDataset(dfg, transforms)\n",
    "    meter = predict(model_marker, dataset, Config, disable_tqdm=True)\n",
    "\n",
    "    transforms = albu.Compose([\n",
    "        albu.PadIfNeeded(always_apply=False, p=1.0, min_height=384, min_width=384),\n",
    "        albu.CenterCrop(always_apply=False, p=1.0, height=384, width=384),\n",
    "    ])\n",
    "    dataset = InferenceDataset(dfg, transforms)\n",
    "    for i in range(len(dataset)):\n",
    "        shape = dataset[i][2]\n",
    "        meter.preds[i].update_shape(shape)\n",
    "    \n",
    "    preds, confs, gts = [], [], []\n",
    "    for idx in range(len(dataset)):\n",
    "        img, gt, shape = dataset[idx] \n",
    "        pred = Boxes(meter.preds[idx]['pascal_voc'][meter.labels[idx] == 0], (shape[0], shape[1]), bbox_format=\"pascal_voc\")\n",
    "        pred = expand_boxes(pred, min_size=64, max_size=64)\n",
    "        scores = meter.confidences[idx][meter.labels[idx] == 0]\n",
    "\n",
    "        if len(gt):\n",
    "            gts.append(Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\"))\n",
    "        else:\n",
    "            gts.append(Boxes(np.zeros((1, 4)), (shape[0], shape[1]), bbox_format=\"yolo\"))\n",
    "            \n",
    "        preds.append(pred)\n",
    "        confs.append(scores)\n",
    "        \n",
    "    # Fuse boxes\n",
    "    boxes_fusion, confs_fusion, hits_fusion, frames = fusion(\n",
    "        preds,\n",
    "        confs,\n",
    "        iou_threshold=0.1,\n",
    "        skip_box_thr=0.05,\n",
    "        conf_threshold=0.1,\n",
    "        hits_threshold=2 if len(dataset) <= 100 else 3,\n",
    "        merge=True,\n",
    "        max_det=1,\n",
    "    )\n",
    "    if not len(boxes_fusion):\n",
    "        print('-> No predictions')\n",
    "#         continue\n",
    "        \n",
    "#     plt.plot(np.concatenate(confs))\n",
    "#     plt.axhline(0.05, c=\"salmon\")\n",
    "#     plt.show()\n",
    "        \n",
    "    if len(boxes_fusion):\n",
    "        boxes_fusion = expand_boxes(boxes_fusion, min_size=CROP_SIZE, max_size=CROP_SIZE)\n",
    "\n",
    "    # GT\n",
    "    if has_extrav:\n",
    "        boxes_fusion_gt, _, _, frames_gt = fusion(\n",
    "            gts,\n",
    "            np.ones((len(gts), 1)),\n",
    "            iou_threshold=0.1,\n",
    "            skip_box_thr=0.01,\n",
    "            conf_threshold=0.1,\n",
    "            hits_threshold=1,\n",
    "            merge=True,\n",
    "        )\n",
    "        boxes_fusion_gt = expand_boxes(boxes_fusion_gt, min_size=CROP_SIZE, max_size=CROP_SIZE)\n",
    "        \n",
    "        if isinstance(boxes_fusion_gt, list):\n",
    "            print('-> Warning, No GT found ')\n",
    "            continue\n",
    "\n",
    "    # Get hits\n",
    "    scores = []\n",
    "    for i, conf in enumerate(confs_fusion):\n",
    "        start, end = frames[i, 0], frames[i, 1]    \n",
    "        for idx in range(start, end):\n",
    "            gt = []\n",
    "            if has_extrav:\n",
    "                gt = [b for j, b in enumerate(boxes_fusion_gt['pascal_voc']) if (idx >= frames_gt[j, 0] and idx <= frames_gt[j, 1])]\n",
    "                gt = np.array(gt)\n",
    "\n",
    "            for box in gt:\n",
    "                iou_score = iou(box, boxes_fusion['pascal_voc'][i])\n",
    "                scores.append(iou_score)\n",
    "\n",
    "    hit = np.max(scores) > 0.1 if len(scores) else False\n",
    "    hits.append(hit)\n",
    "    if hit:\n",
    "        print('-> Correct prediction')\n",
    "#         continue\n",
    "\n",
    "    # Get crops & save\n",
    "    if SAVE:\n",
    "        if has_extrav:\n",
    "            for i, frame in enumerate(frames_gt):\n",
    "                x0, y0, x1, y1 = boxes_fusion_gt['pascal_voc'][i]\n",
    "                \n",
    "                if frame[1] - frame[0] < 5:\n",
    "                    print(f'- Extend crop of size {frame[1] - frame[0] + 1}')\n",
    "                    mid = (frame[1] + frame[0]) // 2\n",
    "                    delta = 3\n",
    "                    frame[0], frame[1] = mid - delta - 1, mid + delta\n",
    "                frame[0] = max(frame[0], 0)\n",
    "                frame[1] = min(frame[1], len(dataset) - 1)\n",
    "                    \n",
    "                crops = []\n",
    "                for idx in range(frame[0], frame[1] + 1):\n",
    "                    img, _, shape = dataset[idx] \n",
    "                    crop = img[y0: y1, x0: x1]\n",
    "                    crops.append(crop)\n",
    "\n",
    "    #                 plt.figure(figsize=(5, 5))\n",
    "    #                 plt.imshow(crop)\n",
    "    #                 plt.show()\n",
    "\n",
    "                if SAVE:\n",
    "                    name = f\"{patient_id}_{series}_{i}_extrav.npy\"\n",
    "                    crops = np.array(crops).astype(np.uint8)[..., 0]\n",
    "                    np.save(SAVE_FOLDER + name, crops)\n",
    "                    print(f\"- Saved crop {name} of frames {np.arange(frame[0], frame[1] + 1, dtype=int)}\")\n",
    "        else:\n",
    "            for i, frame in enumerate(frames):\n",
    "                x0, y0, x1, y1 = boxes_fusion['pascal_voc'][i]\n",
    "\n",
    "                if frame[1] - frame[0] < 5:\n",
    "                    print(f'- Extend crop of size {frame[1] - frame[0] + 1}')\n",
    "                    mid = (frame[1] + frame[0]) // 2\n",
    "                    delta = 3\n",
    "                    frame[0], frame[1] = mid - delta - 1, mid + delta\n",
    "                frame[0] = max(frame[0], 0)\n",
    "                frame[1] = min(frame[1], len(dataset) - 1)\n",
    "                    \n",
    "                crops = []\n",
    "                for idx in range(frame[0], frame[1] + 1):\n",
    "                    img, _, shape = dataset[idx] \n",
    "                    crop = img[y0: y1, x0: x1]\n",
    "                    crops.append(crop)\n",
    "\n",
    "    #                 plt.figure(figsize=(5, 5))\n",
    "    #                 plt.imshow(crop)\n",
    "    #                 plt.show()\n",
    "\n",
    "                if SAVE:\n",
    "                    name = f\"{patient_id}_{series}_{i}_pred.npy\"\n",
    "                    crops = np.array(crops).astype(np.uint8)[..., 0]\n",
    "                    np.save(SAVE_FOLDER + name, crops)\n",
    "                    print(f\"- Saved crop {name} of frames {np.arange(frame[0], frame[1] + 1, dtype=int)}\")\n",
    "        \n",
    "    # Plot\n",
    "    if PLOT and not hit:\n",
    "        for i, conf in enumerate(confs_fusion):\n",
    "            to_plot = np.linspace(frames[i, 0], frames[i, 1], 5, dtype=int)\n",
    "\n",
    "            plt.figure(figsize=(25, 5))\n",
    "            for plot_idx, idx in enumerate(to_plot):\n",
    "    #             plt.figure(figsize=(5, 5))\n",
    "                img, _, shape = dataset[idx] \n",
    "\n",
    "                if has_extrav:\n",
    "                    gt = [b for i, b in enumerate(boxes_fusion_gt['pascal_voc']) if (idx >= frames_gt[i, 0] and idx <= frames_gt[i, 1])]\n",
    "                    gt = np.array(gt)\n",
    "                else:\n",
    "                    gt = np.array([])\n",
    "\n",
    "                merged_boxes = [b for i, b in enumerate(boxes_fusion['pascal_voc']) if ((frames[i, 0] <= idx) and (frames[i, 1] >= idx))]\n",
    "    #             merged_boxes = preds[idx]['pascal_voc']\n",
    "\n",
    "\n",
    "\n",
    "                plt.subplot(1, len(to_plot), plot_idx + 1)\n",
    "                plot_boxes(img, gt, \"pascal_voc\", merged_boxes=merged_boxes)\n",
    "                plt.title(f'Frame {idx} - conf {conf:.3f}')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        if has_extrav and (not hit):\n",
    "            for i, frame in enumerate(frames_gt):\n",
    "                to_plot = np.linspace(frames_gt[i, 0], frames_gt[i, 1], 5, dtype=int)\n",
    "\n",
    "                plt.figure(figsize=(25, 5))\n",
    "                for plot_idx, idx in enumerate(to_plot):\n",
    "                    img, _, shape = dataset[idx] \n",
    "\n",
    "                    gt = [b for i, b in enumerate(boxes_fusion_gt['pascal_voc']) if (idx >= frames_gt[i, 0] and idx <= frames_gt[i, 1])]\n",
    "                    gt = np.array(gt)\n",
    "\n",
    "                    try:\n",
    "                        merged_boxes = [b for i, b in enumerate(boxes_fusion['pascal_voc']) if ((frames[i, 0] <= idx) and (frames[i, 1] >= idx))]\n",
    "                    except:\n",
    "                        merged_boxes = None\n",
    "                        \n",
    "                    merged_boxes = preds[idx]['pascal_voc']\n",
    "                    \n",
    "\n",
    "                    plt.subplot(1, len(to_plot), plot_idx + 1)\n",
    "                    plot_boxes(img, gt, \"pascal_voc\", merged_boxes=merged_boxes)\n",
    "                    plt.title(f'Frame {idx} - Pred conf : {confs[idx][0] :.3f}')\n",
    "                plt.show()\n",
    "\n",
    "#     if study_idx > 100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)\n",
    "\n",
    "if \"fold\" not in df_patient.columns:\n",
    "    folds = pd.read_csv(DATA_PATH + \"folds_4.csv\")\n",
    "    df_img = df_img.merge(folds)\n",
    "    df_patient = df_patient.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [0]:\n",
    "    print(f'\\n- Fold {fold}\\n')\n",
    "    Config.fold = fold\n",
    "    Config.name = f\"rsna_{Config.version}_fold{fold}_{Config.exp}\"\n",
    "    Config.data_dir = f\"../input/yolo/v1/{fold}_train/\"\n",
    "    Config.cfg = f\"../yolox/exps/{Config.name}.py\"\n",
    "    Config.ckpt = f\"../yolox/YOLOX_outputs/{Config.name}/last_epoch_ckpt.pth\"\n",
    "\n",
    "    model_marker = retrieve_yolox_model(Config.cfg, Config.ckpt, size=Config.size)\n",
    "    model_marker = YoloXWrapper(model_marker, Config)\n",
    "    \n",
    "    print('\\n- Predict')\n",
    "    \n",
    "    df_val = df_img[df_img['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "#     df['path'] = df['path'].apply(lambda x: \"../input/imgs/\" + x.split('/')[-1])\n",
    "#     df_val = df_val[df_val['path'].isin(df['path'].values)].reset_index(drop=True)\n",
    "#     df_val['gt_path'] = df_val['path'].apply(\n",
    "#         lambda x: \"../input/yolo/v1/0_train/labels/valid/\" + re.sub(\".png\", \".txt\", x.split('/')[-1])\n",
    "#     )\n",
    "\n",
    "    transforms = get_transfos(size=Config.size)\n",
    "    dataset = InferenceDataset(df_val, transforms)\n",
    "    meter = predict(model_marker, dataset, Config, disable_tqdm=False)\n",
    "\n",
    "    preds = meter.preds\n",
    "        \n",
    "    print('\\n- Save & viz')\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for idx in range(len(dataset)):\n",
    "        pred = meter.preds[idx]['pascal_voc'][0]\n",
    "        score = meter.confidences[idx][0]\n",
    "        \n",
    "        boxes.append(pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        if PLOT or not (idx % 10000):\n",
    "            img, gt, shape = dataset[idx] \n",
    "            if isinstance(img, torch.Tensor):\n",
    "                img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plot_boxes(img, pred[None], \"pascal_voc\")\n",
    "            plt.title(f'Pred - conf={score:.3f}')\n",
    "            plt.show()\n",
    "    \n",
    "    np.save(f'../output/boxes_{Config.name}.npy', np.array(boxes))\n",
    "    np.save(f'../output/confs_{Config.name}.npy', np.array(scores))\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
