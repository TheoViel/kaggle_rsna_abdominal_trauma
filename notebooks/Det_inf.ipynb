{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from data.preparation import *\n",
    "from util.metrics import compute_metrics\n",
    "from inference.det import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patient, df_img = prepare_data(DATA_PATH)\n",
    "\n",
    "# df = pd.read_csv('../input/active_extravasation_bounding_boxes.csv')\n",
    "# df = df.rename(columns={\"pid\": \"patient_id\", \"series_id\": \"series\", \"instance_number\": \"instance\"})\n",
    "# df = df.merge(df_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 5))\n",
    "\n",
    "# for i in range(1, 5):\n",
    "#     plt.subplot(1, 4, i)\n",
    "\n",
    "#     idx = np.random.choice(len(df))\n",
    "#     img = cv2.imread(df['path'].values[idx])\n",
    "#     boxes = df[[\"x1\", \"y1\", \"x2\", \"y2\"]].values[idx]\n",
    "\n",
    "#     plot_boxes(img, boxes, bbox_format=\"pascal_voc\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "    fold = 0\n",
    "#     fold = \"fullfit\"\n",
    "    version = \"v1\"\n",
    "    exp = 2\n",
    "    \n",
    "    if fold != \"fullfit\":\n",
    "        name = f\"rsna_{version}_fold{fold}_{exp}\"\n",
    "    else:\n",
    "        name = f\"rsna_{version}_fullfit_{exp}\"\n",
    "\n",
    "    data_dir = f\"../input/yolo/v1/{fold}_train/\"\n",
    "    cfg = f\"../yolox/exps/{name}.py\"\n",
    "    ckpt = f\"../yolox/YOLOX_outputs/{name}/best_ckpt.pth\"\n",
    "#     ckpt = f\"../yolox/YOLOX_outputs/{name}/last_epoch_ckpt.pth\"\n",
    "    \n",
    "    labels = [\"extravasation\"]\n",
    "\n",
    "    size = (384, 384)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = 0.01\n",
    "    iou_thresh = 0.5\n",
    "    max_per_img = 1\n",
    "\n",
    "    num_workers = 8\n",
    "    val_bs = 64\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marker = retrieve_yolox_model(Config.cfg, Config.ckpt, size=Config.size)\n",
    "model_marker = YoloXWrapper(model_marker, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"path\": glob.glob(Config.data_dir + \"images/valid/*\")})\n",
    "df['gt_path'] = df['path'].apply(lambda x: re.sub(\"images\", \"labels\", x))\n",
    "df['gt_path'] = df['gt_path'].apply(lambda x: re.sub(\".png\", \".txt\", x))\n",
    "\n",
    "# df = df.head(100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- Predict')\n",
    "transforms = get_transfos(size=Config.size)\n",
    "dataset = InferenceDataset(df, transforms)\n",
    "meter = predict(model_marker, dataset, Config, disable_tqdm=False)\n",
    "\n",
    "print('\\n- Update shapes')\n",
    "dataset = InferenceDataset(df, None)\n",
    "for i in range(len(dataset)):\n",
    "    shape = dataset[i][2]\n",
    "    meter.preds[i].update_shape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- Evaluate')\n",
    "\n",
    "f1s = {c: [] for c in Config.labels}\n",
    "recalls = {c: [] for c in Config.labels}\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    img, gt, shape = dataset[idx] \n",
    "\n",
    "    gt = Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\")['pascal_voc']\n",
    "    gt = [gt[dataset.classes[idx] == i] for i in range(len(Config.labels))]\n",
    "\n",
    "    preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(Config.labels))]\n",
    "    scores = [meter.confidences[idx][meter.labels[idx] == i] for i in range(len(Config.labels))]\n",
    "\n",
    "    for i, (t, pm) in enumerate(zip(gt, preds)):\n",
    "        metrics = compute_metrics(pm, t)\n",
    "\n",
    "        f1s[Config.labels[i]].append(metrics['f1_score'])\n",
    "        recalls[Config.labels[i]].append(metrics['recall'])\n",
    "\n",
    "    if PLOT or not (idx % 500):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_boxes(img, gt[0], \"pascal_voc\")\n",
    "        plt.title('Truth')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_boxes(img, preds[0], \"pascal_voc\")\n",
    "        plt.title(f'Pred - conf={scores[0][0]:.3f}')\n",
    "        plt.show()\n",
    "\n",
    "print('\\n')\n",
    "for k, v in f1s.items():\n",
    "    print(f'{k} Recall@1: {np.mean(recalls[k]):.3f}')\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)\n",
    "\n",
    "if \"fold\" not in df_patient.columns:\n",
    "    folds = pd.read_csv(DATA_PATH + \"folds_4.csv\")\n",
    "    df_img = df_img.merge(folds)\n",
    "    df_patient = df_patient.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in [0, 1, 2, 3]:\n",
    "    print(f'\\n- Fold {fold}\\n')\n",
    "    Config.fold = fold\n",
    "    Config.name = f\"rsna_{Config.version}_fold{fold}_{Config.exp}\"\n",
    "    Config.data_dir = f\"../input/yolo/v1/{fold}_train/\"\n",
    "    Config.cfg = f\"../yolox/exps/{Config.name}.py\"\n",
    "    ckpt = f\"../yolox/YOLOX_outputs/{Config.name}/best_ckpt.pth\"\n",
    "\n",
    "    model_marker = retrieve_yolox_model(Config.cfg, Config.ckpt, size=Config.size)\n",
    "    model_marker = YoloXWrapper(model_marker, Config)\n",
    "    \n",
    "    print('\\n- Predict')\n",
    "    df_val = df_img[df_img['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "#     df['path'] = df['path'].apply(lambda x: \"../input/imgs/\" + x.split('/')[-1])\n",
    "#     df_val = df_val[df_val['path'].isin(df['path'].values)].reset_index(drop=True)\n",
    "#     df_val['gt_path'] = df_val['path'].apply(\n",
    "#         lambda x: \"../input/yolo/v1/0_train/labels/valid/\" + re.sub(\".png\", \".txt\", x.split('/')[-1])\n",
    "#     )\n",
    "\n",
    "    transforms = get_transfos(size=Config.size)\n",
    "    dataset = InferenceDataset(df_val, transforms)\n",
    "    meter = predict(model_marker, dataset, Config, disable_tqdm=False)\n",
    "\n",
    "    preds = meter.preds\n",
    "        \n",
    "    print('\\n- Save & viz')\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for idx in range(len(dataset)):\n",
    "        pred = meter.preds[idx]['pascal_voc'][0]\n",
    "        score = meter.confidences[idx][0]\n",
    "        \n",
    "        boxes.append(pred)\n",
    "        scores.append(score)\n",
    "\n",
    "        if PLOT or not (idx % 10000):\n",
    "            img, gt, shape = dataset[idx] \n",
    "            if isinstance(img, torch.Tensor):\n",
    "                img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plot_boxes(img, pred[None], \"pascal_voc\")\n",
    "            plt.title(f'Pred - conf={score:.3f}')\n",
    "            plt.show()\n",
    "    \n",
    "    np.save(f'../output/boxes_{Config.name}.npy', np.array(boxes))\n",
    "    np.save(f'../output/confs_{Config.name}.npy', np.array(scores))\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
