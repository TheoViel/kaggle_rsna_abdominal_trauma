{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_abdominal/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU python-gdcm pydicom pylibjpeg dicomsdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.extract_features import Config\n",
    "from inference.lvl2 import predict as predict_2\n",
    "from inference.lvl2 import PatientFeatureInfDataset, to_sub_format\n",
    "from inference.crop import get_crops\n",
    "\n",
    "from util.torch import load_model_weights\n",
    "from util.plots import plot_mask\n",
    "\n",
    "from data.transforms import get_transfos\n",
    "from data.dataset import AbdominalCropDataset\n",
    "\n",
    "from inference.processing import process, restrict_imgs\n",
    "from inference.lvl1 import predict, AbdominalInfDataset\n",
    "\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from model_zoo.models_lvl2 import define_model as define_model_2\n",
    "from model_zoo.models_seg import define_model as define_model_seg\n",
    "from model_zoo.models_seg import convert_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../input/test_images/\"\n",
    "SAVE_FOLDER = \"../output/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BATCH_SIZE_2 = 512\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "RESTRICT = True\n",
    "HALF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLD = 3\n",
    "# # FOLD = \"fullfit_0\"\n",
    "\n",
    "# EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "#     (\"../logs/2023-09-20/36_r/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-09-27/20_r/\", \"probas_3d\", [FOLD]),  # convnext-tiny rnn 3fs3\n",
    "# #     (\"../logs/2023-09-26/39_r/\", \"probas_3d\", [FOLD]),  # convnext-tiny rnn 2.5D 5fs5\n",
    "# ]\n",
    "\n",
    "# CROP_EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-10-02/41/\", \"crop\", [FOLD])\n",
    "# ]\n",
    "\n",
    "# EXP_FOLDERS_2 = [\n",
    "# #     \"../logs/2023-10-02/27/\"\n",
    "# #     \"../logs/2023-10-02/60/\",\n",
    "#     \"../logs/2023-10-03/22/\",\n",
    "# ]\n",
    "\n",
    "# EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "\n",
    "# FOLDS_2 = [0, 1, 2, 3]\n",
    "# if \"fullfit\" not in str(FOLD):\n",
    "#     FOLDS_2 = [FOLD]\n",
    "    \n",
    "# # HALF = False\n",
    "# Config(json.load(open(EXP_FOLDERS_2[0] + \"config.json\", 'r'))).exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../logs/2023-09-20/14/', 'seg'],\n",
       " ['../logs/2023-09-20/36_r/', 'probas_2d'],\n",
       " ['../logs/2023-10-05/13/', 'probas_2d'],\n",
       " ['../logs/2023-10-02/41/', 'crop']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD = 0\n",
    "# FOLD = \"fullfit_0\"\n",
    "HALF = True\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "    (\"../logs/2023-09-20/36_r/\", \"probas_2d\", [FOLD]),\n",
    "    (\"../logs/2023-10-05/13/\", \"probas_2d\", [FOLD])\n",
    "]\n",
    "\n",
    "CROP_EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-10-06/31/\", \"crop\", [FOLD])\n",
    "    (\"../logs/2023-10-02/41/\", \"crop\", [FOLD])\n",
    "]\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "#     \"../logs/2023-10-07/24/\",  # half\n",
    "    \"../logs/2023-10-07/26/\"\n",
    "]\n",
    "\n",
    "EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "\n",
    "FOLDS_2 = [0, 1, 2, 3]\n",
    "if \"fullfit\" not in str(FOLD):\n",
    "    FOLDS_2 = [FOLD]\n",
    "    \n",
    "Config(json.load(open(EXP_FOLDERS_2[0] + \"config.json\", 'r'))).exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../logs/2023-09-20/14/', 'seg'],\n",
       " ['../logs/2023-10-10/27/', 'probas_2d'],\n",
       " ['../logs/2023-10-06/31/', 'crop']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD = 0\n",
    "# FOLD = \"fullfit_0\"\n",
    "HALF = True\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "#     (\"../logs/2023-09-20/36_r/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-10-05/13/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-10-10/25/\", \"probas_2d\", [FOLD]),  # 0.352 - maxvit_small_tf_384   <-\n",
    "    (\"../logs/2023-10-10/27/\", \"probas_2d\", [FOLD]),  # 0.346  - maxvit_tiny_tf_512   <-\n",
    "]\n",
    "\n",
    "CROP_EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-10-02/11/\", \"crop\", [FOLD]),  # coat_lite_medium  -> 0.326   +0.002\n",
    "#     (\"../logs/2023-10-02/36/\", \"crop\", [FOLD]),   # coat_lite_medium_384 -> 0.326  +0.001\n",
    "#     (\"../logs/2023-10-02/41/\", \"crop\", [FOLD]),  # coatnet_1_rw_224 -> 0.325  +0.001\n",
    "#     (\"../logs/2023-10-05/6/\", \"crop\", [FOLD]),  # coatnet_1_rw_224   -> 0.322\n",
    "#     (\"../logs/2023-10-05/20/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325  +0.001\n",
    "#     (\"../logs/2023-10-05/21/\", \"crop\", [FOLD]),  # coat_lite_medium_384 -> 0.325  +0.001\n",
    "#     (\"../logs/2023-10-05/31/\", \"crop\", [FOLD]), # coatnet_1_rw_224   -> 0.320\n",
    "    (\"../logs/2023-10-06/31/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325\n",
    "]\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "#     \"../logs/2023-10-07/24/\",  # half\n",
    "#     \"../logs/2023-10-07/26/\"\n",
    "    \"../logs/2023-10-11/1/\"\n",
    "]\n",
    "EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "FOLDS_2 = [0, 1, 2, 3]\n",
    "if \"fullfit\" not in str(FOLD):\n",
    "    FOLDS_2 = [FOLD]\n",
    "    \n",
    "Config(json.load(open(EXP_FOLDERS_2[0] + \"config.json\", 'r'))).exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../logs/2023-09-20/14/', 'seg'],\n",
       " ['../logs/2023-09-20/36_r/', 'probas_2d'],\n",
       " ['../logs/2023-10-10/25/', 'probas_2d'],\n",
       " ['../logs/2023-10-10/27/', 'probas_2d'],\n",
       " ['../logs/2023-10-02/11/', 'crop'],\n",
       " ['../logs/2023-10-02/36/', 'crop'],\n",
       " ['../logs/2023-10-02/41/', 'crop'],\n",
       " ['../logs/2023-10-05/6/', 'crop'],\n",
       " ['../logs/2023-10-05/20/', 'crop'],\n",
       " ['../logs/2023-10-05/21/', 'crop'],\n",
       " ['../logs/2023-10-05/31/', 'crop'],\n",
       " ['../logs/2023-10-06/31/', 'crop']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD = 2\n",
    "# FOLD = \"fullfit_0\"\n",
    "HALF = True\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "    (\"../logs/2023-09-20/36_r/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-10-05/13/\", \"probas_2d\", [FOLD]),\n",
    "    (\"../logs/2023-10-10/25/\", \"probas_2d\", [FOLD]),  # 0.352 - maxvit_small_tf_384   <-\n",
    "    (\"../logs/2023-10-10/27/\", \"probas_2d\", [FOLD]),  # 0.346  - maxvit_tiny_tf_512   <-\n",
    "]\n",
    "\n",
    "CROP_EXP_FOLDERS = [\n",
    "    (\"../logs/2023-10-02/11/\", \"crop\", [FOLD]),  # coat_lite_medium  -> 0.326   +0.002\n",
    "    (\"../logs/2023-10-02/36/\", \"crop\", [FOLD]),   # coat_lite_medium_384 -> 0.326  +0.001\n",
    "    (\"../logs/2023-10-02/41/\", \"crop\", [FOLD]),  # coatnet_1_rw_224 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/6/\", \"crop\", [FOLD]),  # coatnet_1_rw_224   -> 0.322\n",
    "    (\"../logs/2023-10-05/20/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/21/\", \"crop\", [FOLD]),  # coat_lite_medium_384 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/31/\", \"crop\", [FOLD]), # coatnet_1_rw_224   -> 0.320\n",
    "    (\"../logs/2023-10-06/31/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325\n",
    "]\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "    \"../logs/2023-10-10/45/\"\n",
    "]\n",
    "EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "FOLDS_2 = [0, 1, 2, 3]\n",
    "if \"fullfit\" not in str(FOLD):\n",
    "    FOLDS_2 = [FOLD]\n",
    "    \n",
    "Config(json.load(open(EXP_FOLDERS_2[0] + \"config.json\", 'r'))).exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# to_upload = [p[0] if isinstance(p, tuple) else p for p in EXP_FOLDERS + CROP_EXP_FOLDERS + EXP_FOLDERS_2 + [EXP_FOLDER_3D]]\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     to_upload,\n",
    "#     \"../output/dataset_2/\",\n",
    "#     \"RSNA Abdomen Weights 2\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seg & Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-24/20/resnet18d_2.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Config3d:\n",
    "    size = 256\n",
    "    plot = FOLD == 0\n",
    "    margin = 5\n",
    "#     n_frames_to_save = 30\n",
    "\n",
    "config = Config(json.load(open(EXP_FOLDER_3D + \"config.json\", \"r\")))\n",
    "\n",
    "model_seg = define_model_seg(\n",
    "    config.decoder_name,\n",
    "    config.name,\n",
    "    num_classes=config.num_classes,\n",
    "    num_classes_aux=config.num_classes_aux,\n",
    "    n_channels=config.n_channels,\n",
    "    increase_stride=config.increase_stride,\n",
    "    pretrained=False,\n",
    ")\n",
    "\n",
    "model_seg = convert_3d(model_seg)\n",
    "model_seg = load_model_weights(model_seg, EXP_FOLDER_3D + f\"{config.name}_{FOLD}.pt\")\n",
    "model_seg = model_seg.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-20/14/efficientnetv2_rw_t_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-20/36_r/convnextv2_tiny_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-10/25/maxvit_small_tf_384_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-10/27/maxvit_tiny_tf_512_2.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, mode, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        head_3d=config.head_3d if hasattr(config, \"head_3d\") else \"\",\n",
    "        n_frames=config.n_frames if hasattr(config, \"n_frames\") else \"\",\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        increase_stride=config.increase_stride if hasattr(config, \"increase_stride\") else False,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Patient 10004 - Series 21057\n",
      "-> Patient 10004 - Series 51033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:22<01:06, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Patient 10005 - Series 18667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:24<00:21, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Patient 10007 - Series 47578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:27<00:07,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Patient 10082 - Series 8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:30<00:00,  7.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "dfs = []\n",
    "for patient in tqdm(sorted(os.listdir(DATA_PATH))):\n",
    "    if FOLD == 0:\n",
    "        if EVAL:\n",
    "            if int(patient) not in patients:\n",
    "                continue\n",
    "        else:\n",
    "            if patient != \"10082\":\n",
    "                continue\n",
    "    elif FOLD == 3:\n",
    "        if patient != \"10004\":\n",
    "            continue\n",
    "\n",
    "    for series in sorted(os.listdir(DATA_PATH + patient)):\n",
    "        print(\"-> Patient\", patient, '- Series', series)\n",
    "\n",
    "        imgs, paths, n_imgs = process(\n",
    "            patient,\n",
    "            series,\n",
    "            data_path=DATA_PATH,\n",
    "            on_gpu=True,\n",
    "            crop_size=384,\n",
    "            restrict=RESTRICT\n",
    "        )\n",
    "\n",
    "        # Seg & Crop\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            x = F.interpolate(imgs.unsqueeze(0).unsqueeze(0), size=(Config3d.size, Config3d.size, Config3d.size), mode=\"nearest\")\n",
    "            pred = model_seg(x)[0].argmax(1, keepdims=True).float()\n",
    "            pred = F.interpolate(pred, size=(len(imgs), 384, 384), mode=\"nearest\")\n",
    "            \n",
    "        seg = pred[0][0]\n",
    "        coords = get_crops(seg)\n",
    "\n",
    "        for (x0, x1, y0, y1, z0, z1), name in zip(coords, ['liver', 'spleen', 'kidney']):\n",
    "            x0, x1 = max(0, x0 - Config3d.margin), min(imgs.shape[0], x1 + Config3d.margin)\n",
    "            y0, y1 = max(0, y0 - Config3d.margin), min(imgs.shape[1], y1 + Config3d.margin)\n",
    "            z0, z1 = max(0, z0 - Config3d.margin), min(imgs.shape[2], z1 + Config3d.margin)\n",
    "\n",
    "            img_crop = (imgs[x0: x1, y0:y1, z0:z1].cpu().numpy() * 255).astype(np.uint8)\n",
    "            np.save(SAVE_FOLDER + f'{patient}_{series}_{name}.npy', img_crop.copy())\n",
    "\n",
    "        # Cls\n",
    "        df = pd.DataFrame({\"path\": paths})\n",
    "        df['patient_id'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['patient'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['series'] = df['path'].apply(lambda x: x.split('_')[1])\n",
    "        df['frame'] = df['path'].apply(lambda x: int(x.split('_')[2][:-4]))\n",
    "        dfs.append(df)\n",
    "\n",
    "        for models_list, (exp_folder, _, _) in zip(models, EXP_FOLDERS):\n",
    "            exp_name = \"_\".join(exp_folder.split('/')[-2:-1])\n",
    "            if \"2023\" not in exp_name:  # locally\n",
    "                exp_name = \"_\".join(exp_folder.split('/')[-3:-1])\n",
    "            \n",
    "            config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "            dataset = AbdominalInfDataset(\n",
    "                df,\n",
    "                frames_chanel=config.frames_chanel if hasattr(config, \"frames_chanel\") else 0,\n",
    "                n_frames=config.n_frames if hasattr(config, \"n_frames\") else 1,\n",
    "                stride=config.stride if hasattr(config, \"stride\") else 1,\n",
    "                imgs=imgs,\n",
    "                paths=paths,\n",
    "            )\n",
    "            if HALF:\n",
    "                dataset.info = dataset.info[::2]\n",
    "\n",
    "            preds = []\n",
    "            for model in models_list:\n",
    "                pred = predict(\n",
    "                    model,\n",
    "                    dataset,\n",
    "                    config.loss_config,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_fp16=USE_FP16,\n",
    "                    num_workers=0,\n",
    "                    resize=config.resize if config.resize[0] != 384 else None\n",
    "                )\n",
    "#                     print(pred.shape)\n",
    "                if HALF:\n",
    "                    pred = np.repeat(pred, 2, axis=0)[:len(df)]\n",
    "#                     print(pred.shape)\n",
    "                preds.append(pred)\n",
    "\n",
    "            if RESTRICT:\n",
    "                pred_padded = np.zeros((n_imgs, pred.shape[-1]))\n",
    "                pred_padded[-len(pred):] = np.mean(preds, 0)\n",
    "            else:\n",
    "                pred_padded = np.mean(preds, 0)\n",
    "\n",
    "            np.save(SAVE_FOLDER + f\"{series}_{exp_name}.npy\", pred_padded)\n",
    "            \n",
    "            if FOLD == 0 and not RESTRICT:\n",
    "                ref = np.load(exp_folder + \"pred_val_0.npy\")\n",
    "                ref = ref[:len(pred)]\n",
    "                \n",
    "                plt.plot(ref - np.mean(preds, 0))\n",
    "                plt.title(np.abs(ref - np.mean(preds, 0)).max())\n",
    "                plt.show()\n",
    "\n",
    "#             break\n",
    "#     break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.groupby(['patient', 'series']).max().reset_index()\n",
    "\n",
    "del model_seg, models, imgs, x, pred, seg, dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = pd.DataFrame({\"img_path\": sorted(glob.glob(SAVE_FOLDER + f'*.npy'))})\n",
    "df_series['patient_id'] = df_series['img_path'].apply(lambda x: x.split('/')[-1].split('_')[0])\n",
    "df_series['series'] = df_series['img_path'].apply(lambda x: x.split('_')[-2])\n",
    "df_series['organ'] = df_series['img_path'].apply(lambda x: x.split('_')[-1][:-4])\n",
    "\n",
    "df_series['target'] = 0\n",
    "df_series = df_series[df_series['organ'].isin(['kidney', 'liver', 'spleen'])].reset_index(drop=True)\n",
    "\n",
    "if FOLD == 0:\n",
    "    df_series = df_series[df_series['patient_id'].astype(int) == 10082].reset_index(drop=True)\n",
    "elif FOLD == 3:\n",
    "    df_series = df_series[df_series['patient_id'].astype(int) == 10004].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-02/11/coat_lite_medium_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-02/36/coat_lite_medium_384_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-02/41/coatnet_1_rw_224_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-05/6/coatnet_1_rw_224_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-05/20/coatnet_rmlp_1_rw2_224_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-05/21/coat_lite_medium_384_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-05/31/coatnet_1_rw_224_2.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-06/31/coatnet_rmlp_1_rw2_224_2.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_fts = []\n",
    "for exp_folder, mode, folds in CROP_EXP_FOLDERS:\n",
    "    \n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        head_3d=config.head_3d if hasattr(config, \"head_3d\") else \"\",\n",
    "        n_frames=config.n_frames if hasattr(config, \"n_frames\") else \"\",\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        increase_stride=config.increase_stride if hasattr(config, \"increase_stride\") else False,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    preds = []\n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        \n",
    "        transfos = get_transfos(\n",
    "            augment=False, resize=config.resize, crop=config.crop\n",
    "        )\n",
    "\n",
    "        dataset = AbdominalCropDataset(\n",
    "            None,\n",
    "            None,\n",
    "            transforms=transfos,\n",
    "            frames_chanel=config.frames_chanel,\n",
    "            n_frames=config.n_frames,\n",
    "            stride=config.stride,\n",
    "            use_mask=config.use_mask,\n",
    "            train=False,\n",
    "            df_series=df_series\n",
    "        )\n",
    "\n",
    "        pred = predict(\n",
    "            model,\n",
    "            dataset,\n",
    "            config.loss_config,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.mean(preds, 0)\n",
    "    crop_fts.append(preds)\n",
    "    \n",
    "crop_fts = np.array(crop_fts) # n_models x 3*n_studies x n_classes\n",
    "np.save(SAVE_FOLDER + \"crop_fts.npy\", crop_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 3, 3)\n",
      "(5, 3, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "crop_fts = np.load(SAVE_FOLDER + \"crop_fts.npy\")\n",
    "\n",
    "crop_fts = crop_fts.reshape(crop_fts.shape[0], crop_fts.shape[1] // 3, 3, crop_fts.shape[2])  # n_models x n_studies x n_organs x 3\n",
    "print(crop_fts.shape)\n",
    "crop_fts = crop_fts.transpose(1, 2, 0, 3)  # n_studies x n_organs x n_models x 3\n",
    "print(crop_fts.shape)\n",
    "crop_fts = crop_fts.reshape(crop_fts.shape[0], crop_fts.shape[1], crop_fts.shape[2] * crop_fts.shape[3])  # n_studies x n_organs x 3 * n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 24)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (crop_fts - np.array(\n",
    "#     [[[9.94628906e-01, 4.81796265e-03, 7.89165497e-04],\n",
    "#     [9.96582031e-01, 2.68936157e-03, 7.21931458e-04],\n",
    "#     [8.11035156e-01, 1.51489258e-01, 3.75366211e-02]],\n",
    "#     [[9.93652344e-01, 5.71060181e-03, 7.65800476e-04],\n",
    "#     [9.96582031e-01, 2.56729126e-03, 6.94274902e-04],\n",
    "#     [9.68750000e-01, 1.92565918e-02, 1.19247437e-02]]]\n",
    "# )).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-10-10/45/rnn_att_2.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS_2:\n",
    "    config_2 = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    dataset = PatientFeatureInfDataset(\n",
    "        df['series'],\n",
    "        config_2.exp_folders,\n",
    "        crop_fts=crop_fts,\n",
    "        max_len=config_2.max_len,\n",
    "        restrict=config_2.restrict,\n",
    "        resize=config_2.resize,\n",
    "        save_folder=SAVE_FOLDER,\n",
    "        half=HALF,\n",
    "    )\n",
    "    \n",
    "    model = define_model_2(\n",
    "        config_2.name,\n",
    "        ft_dim=config_2.ft_dim,\n",
    "        layer_dim=config_2.layer_dim,\n",
    "        n_layers=config_2.n_layers,\n",
    "        dense_dim=config_2.dense_dim,\n",
    "        p=config_2.p,\n",
    "        use_msd=config_2.use_msd,\n",
    "        num_classes=config_2.num_classes,\n",
    "        num_classes_aux=config_2.num_classes_aux,\n",
    "        n_fts=config_2.n_fts,\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "\n",
    "    for fold in FOLDS_2:\n",
    "        weights = exp_folder + f\"{config_2.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    \n",
    "        preds = predict_2(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_2.loss_config,\n",
    "            batch_size=BATCH_SIZE_2,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.338135</td>\n",
       "      <td>0.661865</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.948730</td>\n",
       "      <td>0.030632</td>\n",
       "      <td>0.964111</td>\n",
       "      <td>0.033630</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.964111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.996912</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.920227</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.973145</td>\n",
       "      <td>0.024429</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.979980</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.997469</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.934998</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.005695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10082</td>\n",
       "      <td>0.996449</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>0.113403</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.960449</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.982422</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.004890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0      10004       0.999354      0.000646               0.338135   \n",
       "1      10005       0.996912      0.003088               0.920227   \n",
       "2      10007       0.997469      0.002531               0.934998   \n",
       "3      10082       0.996449      0.003551               0.886597   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.661865        0.020767    0.948730     0.030632   \n",
       "1              0.079773        0.995117    0.004345     0.000446   \n",
       "2              0.065002        0.996582    0.003202     0.000325   \n",
       "3              0.113403        0.994141    0.005432     0.000647   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.964111   0.033630    0.002138        0.021935    0.013996   \n",
       "1       0.973145   0.024429    0.002338        0.979980    0.014793   \n",
       "2       0.968262   0.026596    0.005013        0.980469    0.013954   \n",
       "3       0.960449   0.036835    0.002640        0.982422    0.012505   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.964111  \n",
       "1     0.005245  \n",
       "2     0.005695  \n",
       "3     0.004890  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(all_preds, 0).astype(np.float64)\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    df[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "dfg = df.drop(['series', 'path', 'frame', 'patient_id'], axis=1).groupby('patient').mean().reset_index()\n",
    "sub = to_sub_format(dfg)\n",
    "\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "      <th>fold</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.987284</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>0.736511</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.994629</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.935303</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.699707</td>\n",
       "      <td>0.225464</td>\n",
       "      <td>0.074741</td>\n",
       "      <td>3</td>\n",
       "      <td>0.973862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.996912</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.920227</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>0.024246</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.979980</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.997469</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.935120</td>\n",
       "      <td>0.064880</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10082</td>\n",
       "      <td>0.994019</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.665527</td>\n",
       "      <td>0.334473</td>\n",
       "      <td>0.990723</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.954590</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.019104</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0       10004       0.987284      0.012716               0.736511   \n",
       "1       10005       0.996912      0.003088               0.920227   \n",
       "2       10007       0.997469      0.002531               0.935120   \n",
       "3       10082       0.994019      0.005981               0.665527   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.263489        0.994629    0.004492     0.000896   \n",
       "1              0.079773        0.995117    0.004299     0.000439   \n",
       "2              0.064880        0.996582    0.003222     0.000327   \n",
       "3              0.334473        0.990723    0.008331     0.000835   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.935303   0.059906    0.004932        0.699707    0.225464   \n",
       "1       0.973633   0.024246    0.002316        0.979980    0.014824   \n",
       "2       0.968262   0.026581    0.005032        0.980957    0.013535   \n",
       "3       0.954590   0.041351    0.003941        0.977051    0.019104   \n",
       "\n",
       "   spleen_high  fold      diff  \n",
       "0     0.074741     3  0.973862  \n",
       "1     0.005253     2  0.000488  \n",
       "2     0.005512     2  0.000488  \n",
       "3     0.003687     0  0.221069  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof = pd.read_csv(exp_folder + 'df_oof.csv')\n",
    "df_oof = df_oof[df_oof['patient_id'].isin(sub['patient_id'].values.astype(int))]\n",
    "\n",
    "df_oof = df_oof[[\"patient_id\", \"fold\"] + list(df_oof.columns[-11:])]\n",
    "df_oof.columns = [\"patient_id\", \"fold\", \"bowel_injury\", \"extravasation_injury\"] + list(sub.columns[-9:])\n",
    "df_oof[\"extravasation_healthy\"] = 1 - df_oof[\"extravasation_injury\"]\n",
    "df_oof[\"bowel_healthy\"] = 1 - df_oof[\"bowel_injury\"]\n",
    "\n",
    "df_oof = df_oof.sort_values('patient_id', ignore_index=True)\n",
    "\n",
    "df_oof['diff'] = (sub[sub.columns[1:]] - df_oof[sub.columns[1:]]).abs().max(1)\n",
    "\n",
    "df_oof = df_oof[list(sub.columns) + ['fold', 'diff']]\n",
    "# df_oof[df_oof['fold'] == FOLD]\n",
    "df_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "      <th>fold</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10082</td>\n",
       "      <td>0.996365</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.873169</td>\n",
       "      <td>0.126831</td>\n",
       "      <td>0.987305</td>\n",
       "      <td>0.010323</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.02359</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.96582</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0       10082       0.996365      0.003635               0.873169   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.126831        0.987305    0.010323     0.002151   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.974121    0.02359    0.002115         0.96582    0.027161   \n",
       "\n",
       "   spleen_high  fold      diff  \n",
       "0     0.006821     0  0.000732  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof = pd.read_csv(exp_folder + 'df_oof.csv')\n",
    "df_oof = df_oof[df_oof['patient_id'].isin(sub['patient_id'].values.astype(int))]\n",
    "\n",
    "df_oof = df_oof[[\"patient_id\", \"fold\"] + list(df_oof.columns[-11:])]\n",
    "df_oof.columns = [\"patient_id\", \"fold\", \"bowel_injury\", \"extravasation_injury\"] + list(sub.columns[-9:])\n",
    "df_oof[\"extravasation_healthy\"] = 1 - df_oof[\"extravasation_injury\"]\n",
    "df_oof[\"bowel_healthy\"] = 1 - df_oof[\"bowel_injury\"]\n",
    "\n",
    "df_oof = df_oof.sort_values('patient_id', ignore_index=True)\n",
    "\n",
    "df_oof['diff'] = (sub[sub.columns[1:]] - df_oof[sub.columns[1:]]).abs().max(1)\n",
    "\n",
    "df_oof = df_oof[list(sub.columns) + ['fold', 'diff']]\n",
    "# df_oof[df_oof['fold'] == FOLD]\n",
    "df_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv(SAVE_FOLDER + \"submission.csv\", index=False)\n",
    "# sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
