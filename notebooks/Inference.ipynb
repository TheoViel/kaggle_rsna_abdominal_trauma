{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to validate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_rsna_abdominal/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU python-gdcm pydicom pylibjpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n",
    "    \"\"\"\n",
    "    # Correct DICOM pixel_array if PixelRepresentation == 1.\n",
    "    pixel_array = dcm.pixel_array\n",
    "    if dcm.PixelRepresentation == 1:\n",
    "        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n",
    "        dtype = pixel_array.dtype \n",
    "        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n",
    "#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n",
    "\n",
    "    intercept = float(dcm.RescaleIntercept)\n",
    "    slope = float(dcm.RescaleSlope)\n",
    "    center = int(dcm.WindowCenter)\n",
    "    width = int(dcm.WindowWidth)\n",
    "    low = center - width / 2\n",
    "    high = center + width / 2    \n",
    "    \n",
    "    pixel_array = (pixel_array * slope) + intercept\n",
    "    pixel_array = np.clip(pixel_array, low, high)\n",
    "\n",
    "    return pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pydicom\n",
    "\n",
    "\n",
    "def process(patient, study, size=None, save_folder=\"\", data_path=\"\"):\n",
    "    all_imgs = {}\n",
    "    imgs = {}\n",
    "    for f in sorted(glob.glob(data_path + f\"{patient}/{study}/*.dcm\")):\n",
    "        dicom = pydicom.dcmread(f)\n",
    "\n",
    "        pos_z = dicom[(0x20, 0x32)].value[-1]\n",
    "\n",
    "        img = standardize_pixel_array(dicom)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "\n",
    "        if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            img = 1 - img\n",
    "\n",
    "        imgs[pos_z] = img\n",
    "\n",
    "    for i, k in enumerate(sorted(imgs.keys())):\n",
    "        img = imgs[k]\n",
    "\n",
    "        if size is not None:\n",
    "            img = cv2.resize(img, (size, size))\n",
    "\n",
    "        all_imgs[save_folder + f\"{patient}_{study}_{i}.png\"] =  (img * 255).astype(np.uint8)\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../input/train_images/\"\n",
    "SAVE_FOLDER = \"../output/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BATCH_SIZE_2 = 1024\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "FOLDS = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import Abdominal2DInfDataset\n",
    "from data.transforms import get_transfos\n",
    "from inference.extract_features import predict, Config\n",
    "\n",
    "from util.torch import load_model_weights\n",
    "from model_zoo.models import define_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folders = [\n",
    "    (\"../logs/2023-09-06/4/\", \"seg\"),\n",
    "    (\"../logs/2023-09-15/22/\", \"probas\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-06/4/tf_efficientnetv2_s_0.pt\n",
      "\n",
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-15/22/tf_efficientnetv2_s_0.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, mode in exp_folders:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    \n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    for fold in FOLDS:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.71s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for patient in tqdm(sorted(os.listdir(DATA_PATH))):\n",
    "    for study in sorted(os.listdir(DATA_PATH + patient)):\n",
    "        \n",
    "#         print(\"-> Patient\", patient, '- Study', study)\n",
    "        imgs = process(patient, study, data_path=DATA_PATH)\n",
    "\n",
    "        df = pd.DataFrame({\"path\": imgs.keys()})\n",
    "        df['patient'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['series'] = df['path'].apply(lambda x: x.split('_')[1])\n",
    "        df['frame'] = df['path'].apply(lambda x: x.split('_')[2][:-4])\n",
    "        dfs.append(df)\n",
    "        \n",
    "        for models_list, (exp_folder, _) in zip(models, exp_folders):\n",
    "            exp_name = \"_\".join(exp_folder.split('/')[-3:-1])\n",
    "            config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "            \n",
    "            dataset = Abdominal2DInfDataset(\n",
    "                df,\n",
    "                transforms=get_transfos(augment=False, resize=config.resize),\n",
    "                frames_chanel=config.frames_chanel if hasattr(config, \"frames_chanel\") else 0,\n",
    "                imgs=imgs\n",
    "            )\n",
    "\n",
    "            preds = []\n",
    "            for model in models_list:\n",
    "                pred, _ = predict(\n",
    "                    model,\n",
    "                    dataset,\n",
    "                    config.loss_config,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_fp16=USE_FP16,\n",
    "                    num_workers=NUM_WORKERS,\n",
    "                )\n",
    "                preds.append(pred)\n",
    "\n",
    "            np.save(SAVE_FOLDER + f\"{study}_{exp_name}.npy\", np.mean(preds, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref = np.load(exp_folder + \"pred_val_0.npy\")\n",
    "# ref = ref[:len(pred)]\n",
    "# np.abs(ref - pred).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(preds[0])\n",
    "# plt.plot(preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.groupby(['patient', 'series']).max().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import PatientFeatureInfDataset\n",
    "from model_zoo.models_lvl2 import define_model as define_model_2\n",
    "from inference.lvl2 import predict as predict_2\n",
    "from inference.lvl2 import to_sub_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS_2 = [\n",
    "    \"../logs/2023-09-15/36/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> Loading encoder weights from ../logs/2023-09-15/36/rnn_0.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS_2:\n",
    "    config_2 = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    \n",
    "    dataset = PatientFeatureInfDataset(\n",
    "        df['series'], config_2.exp_folders, max_len=config_2.max_len, save_folder=SAVE_FOLDER\n",
    "    )\n",
    "    \n",
    "    model = define_model_2(\n",
    "        config_2.name,\n",
    "        ft_dim=config_2.ft_dim,\n",
    "        layer_dim=config_2.layer_dim,\n",
    "        n_layers=config_2.n_layers,\n",
    "        dense_dim=config_2.dense_dim,\n",
    "        p=config_2.p,\n",
    "        use_msd=config_2.use_msd,\n",
    "        num_classes=config_2.num_classes,\n",
    "        num_classes_aux=config_2.num_classes_aux,\n",
    "        n_fts=config_2.n_fts,\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "    \n",
    "    models = []\n",
    "    for fold in FOLDS:\n",
    "        weights = exp_folder + f\"{config_2.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    \n",
    "        preds = predict_2(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_2.loss_config,\n",
    "            batch_size=BATCH_SIZE_2,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(all_preds, 0)\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    df[f'pred_{i}'] = preds[:, i]\n",
    "    \n",
    "dfg = df.drop(['series', 'path', 'frame'], axis=1).groupby('patient').mean().reset_index()\n",
    "sub = to_sub_format(dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (np.load(exp_folder + \"pred_oof.npy\")[0] - preds).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10082</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>0.02948</td>\n",
       "      <td>0.510742</td>\n",
       "      <td>0.489014</td>\n",
       "      <td>0.978516</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.954102</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.705566</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.126221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0      10082       0.970703       0.02948               0.510742   \n",
       "\n",
       "   extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0              0.489014        0.978516    0.012634     0.009033   \n",
       "\n",
       "   liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0       0.954102   0.042084    0.003614        0.705566    0.168213   \n",
       "\n",
       "   spleen_high  \n",
       "0     0.126221  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv(SAVE_FOLDER + \"submission.csv\", index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
