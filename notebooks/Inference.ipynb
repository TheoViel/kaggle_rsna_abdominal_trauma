{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to validate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import upload_to_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_to_kaggle(\n",
    "    [\"../logs/2023-09-20/14/\", \"../logs/2023-09-20/36/\", \"../logs/2023-09-28/15/\"],\n",
    "    \"../output/dataset/\",\n",
    "    \"RSNA Abdomen Weights 1\",\n",
    "    update_folders=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU python-gdcm pydicom pylibjpeg dicomsdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.extract_features import Config  # predict, \n",
    "from inference.lvl2 import predict as predict_2\n",
    "from inference.lvl2 import PatientFeatureInfDataset, to_sub_format\n",
    "\n",
    "from util.torch import load_model_weights\n",
    "\n",
    "from inference.processing import process, restrict_imgs\n",
    "from inference.lvl1 import predict, AbdominalInfDataset\n",
    "from data.transforms import get_transfos\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from model_zoo.models_lvl2 import define_model as define_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../input/test_images/\"\n",
    "SAVE_FOLDER = \"../output/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BATCH_SIZE_2 = 512\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "RESTRICT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "    (\"../logs/2023-09-20/36/\", \"probas_2d\", [FOLD]),\n",
    "]\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "    \"../logs/2023-09-28/15/\"\n",
    "]\n",
    "# FOLDS_2 = [0, 1, 2, 3]\n",
    "FOLDS_2 = [FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, mode, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        head_3d=config.head_3d if hasattr(config, \"head_3d\") else \"\",\n",
    "        n_frames=config.n_frames if hasattr(config, \"n_frames\") else \"\",\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        increase_stride=config.increase_stride if hasattr(config, \"increase_stride\") else False,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfs = []\n",
    "for patient in tqdm(sorted(os.listdir(DATA_PATH))):\n",
    "    if FOLD == 0:\n",
    "        if patient != \"10082\":\n",
    "            continue\n",
    "\n",
    "    for study in sorted(os.listdir(DATA_PATH + patient)):\n",
    "        print(\"-> Patient\", patient, '- Study', study)\n",
    "\n",
    "        imgs, n_imgs = process(patient, study, data_path=DATA_PATH, on_gpu=True, crop_size=384, restrict=RESTRICT)\n",
    "\n",
    "#         img_paths = sorted(glob.glob(f'../input/imgs/{patient}_{study}*'))\n",
    "#         if RESTRICT:\n",
    "#             img_paths, n_imgs = restrict_imgs(img_paths)\n",
    "#         imgs = {k.split('/')[-1]: cv2.imread(k, 0).astype(np.float32) / 255 for k in img_paths}  # \n",
    "\n",
    "        df = pd.DataFrame({\"path\": imgs.keys()})\n",
    "        df['patient_id'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['patient'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['series'] = df['path'].apply(lambda x: x.split('_')[1])\n",
    "        df['frame'] = df['path'].apply(lambda x: int(x.split('_')[2][:-4]))\n",
    "        dfs.append(df)\n",
    "        \n",
    "        for models_list, (exp_folder, _, _) in zip(models, EXP_FOLDERS):\n",
    "            exp_name = \"_\".join(exp_folder.split('/')[-2:-1])\n",
    "            if \"2023\" not in exp_name:  # locally\n",
    "                exp_name = \"_\".join(exp_folder.split('/')[-3:-1])\n",
    "            \n",
    "            config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "            \n",
    "            transfos = get_transfos(\n",
    "                augment=False,\n",
    "                resize=(384, 384),\n",
    "                crop=True\n",
    "            )\n",
    "            dataset = AbdominalInfDataset(\n",
    "                df,\n",
    "                transforms=transfos,\n",
    "                frames_chanel=config.frames_chanel if hasattr(config, \"frames_chanel\") else 0,\n",
    "                n_frames=config.n_frames if hasattr(config, \"n_frames\") else 1,\n",
    "                stride=config.stride if hasattr(config, \"stride\") else 1,\n",
    "                imgs=imgs\n",
    "            )\n",
    "\n",
    "            preds = []\n",
    "            for model in models_list:\n",
    "                pred, _ = predict(\n",
    "                    model,\n",
    "                    dataset,\n",
    "                    config.loss_config,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_fp16=USE_FP16,\n",
    "                    num_workers=NUM_WORKERS,\n",
    "                )\n",
    "                preds.append(pred)\n",
    "\n",
    "            if RESTRICT:\n",
    "                pred_padded = np.zeros((n_imgs, pred.shape[-1]))\n",
    "                pred_padded[-len(pred):] = np.mean(preds, 0)\n",
    "            else:\n",
    "                pred_padded = np.mean(preds, 0)\n",
    "\n",
    "            np.save(SAVE_FOLDER + f\"{study}_{exp_name}.npy\", pred_padded)\n",
    "            \n",
    "#             ref = np.load(exp_folder + \"pred_val_0.npy\")\n",
    "#             ref = ref[:len(pred)]\n",
    "#             print(np.abs(ref - np.mean(preds, 0)).max())\n",
    "            \n",
    "#             break\n",
    "#     break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.groupby(['patient', 'series']).max().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS_2:\n",
    "    config_2 = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    dataset = PatientFeatureInfDataset(\n",
    "        df['series'],\n",
    "        config_2.exp_folders,\n",
    "        max_len=config_2.max_len,\n",
    "        restrict=config_2.restrict,\n",
    "        resize=config_2.resize,\n",
    "        save_folder=SAVE_FOLDER\n",
    "    )\n",
    "    \n",
    "    model = define_model_2(\n",
    "        config_2.name,\n",
    "        ft_dim=config_2.ft_dim,\n",
    "        layer_dim=config_2.layer_dim,\n",
    "        n_layers=config_2.n_layers,\n",
    "        dense_dim=config_2.dense_dim,\n",
    "        p=config_2.p,\n",
    "        use_msd=config_2.use_msd,\n",
    "        num_classes=config_2.num_classes,\n",
    "        num_classes_aux=config_2.num_classes_aux,\n",
    "        n_fts=config_2.n_fts,\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "\n",
    "    for fold in FOLDS_2:\n",
    "        weights = exp_folder + f\"{config_2.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    \n",
    "        preds = predict_2(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_2.loss_config,\n",
    "            batch_size=BATCH_SIZE_2,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(all_preds, 0).astype(np.float64)\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    df[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "dfg = df.drop(['series', 'path', 'frame', 'patient_id'], axis=1).groupby('patient').mean().reset_index()\n",
    "sub = to_sub_format(dfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.read_csv(exp_folder + 'df_oof.csv')\n",
    "df_oof = df_oof[df_oof['patient_id'].isin(sub['patient_id'].values.astype(int))]\n",
    "\n",
    "df_oof = df_oof[[\"patient_id\", \"fold\"] + list(df_oof.columns[-11:])]\n",
    "df_oof.columns = [\"patient_id\", \"fold\", \"bowel_injury\", \"extravasation_injury\"] + list(sub.columns[-9:])\n",
    "df_oof[\"extravasation_healthy\"] = 1 - df_oof[\"extravasation_injury\"]\n",
    "df_oof[\"bowel_healthy\"] = 1 - df_oof[\"bowel_injury\"]\n",
    "\n",
    "df_oof = df_oof.sort_values('patient_id', ignore_index=True)\n",
    "\n",
    "\n",
    "df_oof['diff'] = (sub[sub.columns[1:]] - df_oof[sub.columns[1:]]).abs().max(1)\n",
    "\n",
    "df_oof = df_oof[list(sub.columns) + ['fold', 'diff']]\n",
    "# df_oof[df_oof['fold'] == FOLD]\n",
    "df_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.read_csv(exp_folder + 'df_oof.csv')\n",
    "df_oof = df_oof[df_oof['patient_id'].isin(sub['patient_id'].values.astype(int))]\n",
    "\n",
    "df_oof = df_oof[[\"patient_id\", \"fold\"] + list(df_oof.columns[-11:])]\n",
    "df_oof.columns = [\"patient_id\", \"fold\", \"bowel_injury\", \"extravasation_injury\"] + list(sub.columns[-9:])\n",
    "df_oof[\"extravasation_healthy\"] = 1 - df_oof[\"extravasation_injury\"]\n",
    "df_oof[\"bowel_healthy\"] = 1 - df_oof[\"bowel_injury\"]\n",
    "\n",
    "df_oof = df_oof.sort_values('patient_id', ignore_index=True)\n",
    "\n",
    "\n",
    "df_oof['diff'] = (sub[sub.columns[1:]] - df_oof[sub.columns[1:]]).abs().max(1)\n",
    "\n",
    "df_oof = df_oof[list(sub.columns) + ['fold', 'diff']]\n",
    "# df_oof[df_oof['fold'] == FOLD]\n",
    "df_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv(SAVE_FOLDER + \"submission.csv\", index=False)\n",
    "# sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
