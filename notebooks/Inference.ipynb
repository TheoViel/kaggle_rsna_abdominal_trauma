{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to infer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU python-gdcm pydicom pylibjpeg dicomsdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.extract_features import Config\n",
    "from inference.lvl2 import predict as predict_2\n",
    "from inference.lvl2 import PatientFeatureInfDataset, to_sub_format\n",
    "from inference.crop import get_crops\n",
    "\n",
    "from util.torch import load_model_weights\n",
    "from util.plots import plot_mask\n",
    "\n",
    "from data.transforms import get_transfos\n",
    "from data.dataset import AbdominalCropDataset\n",
    "\n",
    "from inference.processing import process, restrict_imgs\n",
    "from inference.lvl1 import predict, AbdominalInfDataset\n",
    "\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from model_zoo.models_lvl2 import define_model as define_model_2\n",
    "from model_zoo.models_seg import define_model as define_model_seg\n",
    "from model_zoo.models_seg import convert_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../input/test_images/\"\n",
    "SAVE_FOLDER = \"../output/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BATCH_SIZE_2 = 512\n",
    "USE_FP16 = True\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "RESTRICT = True\n",
    "HALF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 2\n",
    "# FOLD = \"fullfit_0\"\n",
    "HALF = True\n",
    "\n",
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "    (\"../logs/2023-09-20/36_r/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-10-05/13/\", \"probas_2d\", [FOLD]),\n",
    "    (\"../logs/2023-10-10/25/\", \"probas_2d\", [FOLD]),  # 0.352 - maxvit_small_tf_384   <-\n",
    "    (\"../logs/2023-10-10/27/\", \"probas_2d\", [FOLD]),  # 0.346  - maxvit_tiny_tf_512   <-\n",
    "]\n",
    "\n",
    "CROP_EXP_FOLDERS = [\n",
    "    (\"../logs/2023-10-02/11/\", \"crop\", [FOLD]),  # coat_lite_medium  -> 0.326   +0.002\n",
    "    (\"../logs/2023-10-02/36/\", \"crop\", [FOLD]),   # coat_lite_medium_384 -> 0.326  +0.001\n",
    "    (\"../logs/2023-10-02/41/\", \"crop\", [FOLD]),  # coatnet_1_rw_224 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/6/\", \"crop\", [FOLD]),  # coatnet_1_rw_224   -> 0.322\n",
    "    (\"../logs/2023-10-05/20/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/21/\", \"crop\", [FOLD]),  # coat_lite_medium_384 -> 0.325  +0.001\n",
    "    (\"../logs/2023-10-05/31/\", \"crop\", [FOLD]), # coatnet_1_rw_224   -> 0.320\n",
    "    (\"../logs/2023-10-06/31/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -> 0.325\n",
    "]\n",
    "\n",
    "EXP_FOLDERS_2 = [\n",
    "    \"../logs/2023-10-10/45/\",\n",
    "    \"../logs/2023-10-10/42/\",\n",
    "    \"../logs/2023-10-10/46/\",\n",
    "]\n",
    "EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "FOLDS_2 = [0, 1, 2, 3]\n",
    "if \"fullfit\" not in str(FOLD):\n",
    "    FOLDS_2 = [FOLD]\n",
    "    \n",
    "    \n",
    "for f in EXP_FOLDERS_2:\n",
    "    folders = Config(json.load(open(f + \"config.json\", 'r'))).exp_folders\n",
    "    print(f)\n",
    "    print([f[0] for f in folders if \"probas\" in f[1]])\n",
    "    print([f[0] for f in folders if \"crop\" in f[1]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLD = 2\n",
    "# # FOLD = \"fullfit_0\"\n",
    "# HALF = True\n",
    "\n",
    "# EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-09-20/14/\", \"seg\", [FOLD]),\n",
    "#     (\"../logs/2023-10-05/13/\", \"probas_2d\", [FOLD]),\n",
    "#     (\"../logs/2023-10-06/38/\", \"probas_2d\", [FOLD]),  # 0.361 convnextv2_tiny\n",
    "#     (\"../logs/2023-10-10/27/\", \"probas_2d\", [FOLD]),  # 0.346  - maxvit_tiny_tf_512   <-\n",
    "# ]\n",
    "\n",
    "# CROP_EXP_FOLDERS = [\n",
    "#     (\"../logs/2023-10-05/6/\", \"crop\", [FOLD]),   # coatnet_1_rw_224 -1 7        -> 0.322 +0.0008\n",
    "#     (\"../logs/2023-10-05/31/\", \"crop\", [FOLD]),  # coatnet_1_rw_224 -1 11       -> 0.320  +0.0016\n",
    "#     (\"../logs/2023-10-06/31/\", \"crop\", [FOLD]),  # coatnet_rmlp_1_rw2_224 -1 11 -> 0.325  +0.0021\n",
    "#     (\"../logs/2023-10-12/1/\", \"crop\", [FOLD]),  # coatnet_1_rw_224 -1 11 transfo -> -0.0001  - SWAP FOR  05/21 - 0.3109\n",
    "#     (\"../logs/2023-10-12/8/\", \"crop\", [FOLD]),  # coat_lite_medium transfo -1 11 lstm att -> -0.0001    - SWAP FOR  05/21 0.3110\n",
    "#     (\"../logs/2023-10-12/5/\", \"crop\", [FOLD]),  # coat_lite_medium_384\n",
    "# ]\n",
    "\n",
    "# EXP_FOLDERS_2 = [\n",
    "#     \"../logs/2023-10-13/0/\",  # 0.3154\n",
    "#     \"../logs/2023-10-13/1/\",  # 0.3130\n",
    "# ]\n",
    "# EXP_FOLDER_3D = \"../logs/2023-09-24/20/\"\n",
    "\n",
    "# FOLDS_2 = [0, 1, 2, 3]\n",
    "# if \"fullfit\" not in str(FOLD):\n",
    "#     FOLDS_2 = [FOLD]\n",
    "\n",
    "# for f in EXP_FOLDERS_2:\n",
    "#     folders = Config(json.load(open(f + \"config.json\", 'r'))).exp_folders\n",
    "#     print(f)\n",
    "#     print([f[0] for f in folders if \"probas\" in f[1]])\n",
    "#     print([f[0] for f in folders if \"crop\" in f[1]])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.logger import upload_to_kaggle\n",
    "\n",
    "# to_upload = [p[0] if isinstance(p, tuple) else p for p in EXP_FOLDERS + CROP_EXP_FOLDERS + EXP_FOLDERS_2 + [EXP_FOLDER_3D]]\n",
    "\n",
    "# upload_to_kaggle(\n",
    "#     to_upload,\n",
    "#     \"../output/dataset/\",\n",
    "#     \"RSNA Abdomen Weights\",\n",
    "#     update_folders=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seg & Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config3d:\n",
    "    size = 256\n",
    "    plot = FOLD == 0\n",
    "    margin = 5\n",
    "#     n_frames_to_save = 30\n",
    "\n",
    "config = Config(json.load(open(EXP_FOLDER_3D + \"config.json\", \"r\")))\n",
    "\n",
    "model_seg = define_model_seg(\n",
    "    config.decoder_name,\n",
    "    config.name,\n",
    "    num_classes=config.num_classes,\n",
    "    num_classes_aux=config.num_classes_aux,\n",
    "    n_channels=config.n_channels,\n",
    "    increase_stride=config.increase_stride,\n",
    "    pretrained=False,\n",
    ")\n",
    "\n",
    "model_seg = convert_3d(model_seg)\n",
    "model_seg = load_model_weights(model_seg, EXP_FOLDER_3D + f\"{config.name}_{FOLD}.pt\")\n",
    "model_seg = model_seg.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for exp_folder, mode, folds in EXP_FOLDERS:\n",
    "    models_ = []\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        head_3d=config.head_3d if hasattr(config, \"head_3d\") else \"\",\n",
    "        n_frames=config.n_frames if hasattr(config, \"n_frames\") else \"\",\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        increase_stride=config.increase_stride if hasattr(config, \"increase_stride\") else False,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        models_.append(model)\n",
    "        \n",
    "    models.append(models_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "dfs = []\n",
    "for patient in tqdm(sorted(os.listdir(DATA_PATH))):\n",
    "    if FOLD == 0:\n",
    "        if EVAL:\n",
    "            if int(patient) not in patients:\n",
    "                continue\n",
    "        else:\n",
    "            if patient != \"10082\":\n",
    "                continue\n",
    "    elif FOLD == 3:\n",
    "        if patient != \"10004\":\n",
    "            continue\n",
    "\n",
    "    for series in sorted(os.listdir(DATA_PATH + patient)):\n",
    "        print(\"-> Patient\", patient, '- Series', series)\n",
    "\n",
    "        imgs, paths, n_imgs = process(\n",
    "            patient,\n",
    "            series,\n",
    "            data_path=DATA_PATH,\n",
    "            on_gpu=True,\n",
    "            crop_size=384,\n",
    "            restrict=RESTRICT\n",
    "        )\n",
    "\n",
    "        # Seg & Crop\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            x = F.interpolate(imgs.unsqueeze(0).unsqueeze(0), size=(Config3d.size, Config3d.size, Config3d.size), mode=\"nearest\")\n",
    "            pred = model_seg(x)[0].argmax(1, keepdims=True).float()\n",
    "            pred = F.interpolate(pred, size=(len(imgs), 384, 384), mode=\"nearest\")\n",
    "            \n",
    "        seg = pred[0][0]\n",
    "        coords = get_crops(seg)\n",
    "\n",
    "        for (x0, x1, y0, y1, z0, z1), name in zip(coords, ['liver', 'spleen', 'kidney']):\n",
    "            x0, x1 = max(0, x0 - Config3d.margin), min(imgs.shape[0], x1 + Config3d.margin)\n",
    "            y0, y1 = max(0, y0 - Config3d.margin), min(imgs.shape[1], y1 + Config3d.margin)\n",
    "            z0, z1 = max(0, z0 - Config3d.margin), min(imgs.shape[2], z1 + Config3d.margin)\n",
    "\n",
    "            img_crop = (imgs[x0: x1, y0:y1, z0:z1].cpu().numpy() * 255).astype(np.uint8)\n",
    "            np.save(SAVE_FOLDER + f'{patient}_{series}_{name}.npy', img_crop.copy())\n",
    "\n",
    "        # Cls\n",
    "        df = pd.DataFrame({\"path\": paths})\n",
    "        df['patient_id'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['patient'] = df['path'].apply(lambda x: x.split('_')[0])\n",
    "        df['series'] = df['path'].apply(lambda x: x.split('_')[1])\n",
    "        df['frame'] = df['path'].apply(lambda x: int(x.split('_')[2][:-4]))\n",
    "        dfs.append(df)\n",
    "\n",
    "        for models_list, (exp_folder, _, _) in zip(models, EXP_FOLDERS):\n",
    "            exp_name = \"_\".join(exp_folder.split('/')[-2:-1])\n",
    "            if \"2023\" not in exp_name:  # locally\n",
    "                exp_name = \"_\".join(exp_folder.split('/')[-3:-1])\n",
    "            \n",
    "            config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "            dataset = AbdominalInfDataset(\n",
    "                df,\n",
    "                frames_chanel=config.frames_chanel if hasattr(config, \"frames_chanel\") else 0,\n",
    "                n_frames=config.n_frames if hasattr(config, \"n_frames\") else 1,\n",
    "                stride=config.stride if hasattr(config, \"stride\") else 1,\n",
    "                imgs=imgs,\n",
    "                paths=paths,\n",
    "            )\n",
    "            if HALF:\n",
    "                dataset.info = dataset.info[::2]\n",
    "\n",
    "            preds = []\n",
    "            for model in models_list:\n",
    "                pred = predict(\n",
    "                    model,\n",
    "                    dataset,\n",
    "                    config.loss_config,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    use_fp16=USE_FP16,\n",
    "                    num_workers=0,\n",
    "                    resize=config.resize if config.resize[0] != 384 else None\n",
    "                )\n",
    "#                     print(pred.shape)\n",
    "                if HALF:\n",
    "                    pred = np.repeat(pred, 2, axis=0)[:len(df)]\n",
    "#                     print(pred.shape)\n",
    "                preds.append(pred)\n",
    "\n",
    "            if RESTRICT:\n",
    "                pred_padded = np.zeros((n_imgs, pred.shape[-1]))\n",
    "                pred_padded[-len(pred):] = np.mean(preds, 0)\n",
    "            else:\n",
    "                pred_padded = np.mean(preds, 0)\n",
    "\n",
    "            np.save(SAVE_FOLDER + f\"{series}_{exp_name}.npy\", pred_padded)\n",
    "            \n",
    "            if FOLD == 0 and not RESTRICT:\n",
    "                ref = np.load(exp_folder + \"pred_val_0.npy\")\n",
    "                ref = ref[:len(pred)]\n",
    "                \n",
    "                plt.plot(ref - np.mean(preds, 0))\n",
    "                plt.title(np.abs(ref - np.mean(preds, 0)).max())\n",
    "                plt.show()\n",
    "\n",
    "#             break\n",
    "#     break\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.groupby(['patient', 'series']).max().reset_index()\n",
    "\n",
    "del model_seg, models, imgs, x, pred, seg, dataset\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = pd.DataFrame({\"img_path\": sorted(glob.glob(SAVE_FOLDER + f'*.npy'))})\n",
    "df_series['patient_id'] = df_series['img_path'].apply(lambda x: x.split('/')[-1].split('_')[0])\n",
    "df_series['series'] = df_series['img_path'].apply(lambda x: x.split('_')[-2])\n",
    "df_series['organ'] = df_series['img_path'].apply(lambda x: x.split('_')[-1][:-4])\n",
    "\n",
    "df_series['target'] = 0\n",
    "df_series = df_series[df_series['organ'].isin(['kidney', 'liver', 'spleen'])].reset_index(drop=True)\n",
    "\n",
    "if FOLD == 0:\n",
    "    df_series = df_series[df_series['patient_id'].astype(int) == 10082].reset_index(drop=True)\n",
    "elif FOLD == 3:\n",
    "    df_series = df_series[df_series['patient_id'].astype(int) == 10004].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fts = []\n",
    "for exp_folder, mode, folds in CROP_EXP_FOLDERS:\n",
    "    \n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    model = define_model(\n",
    "        config.name,\n",
    "        drop_rate=config.drop_rate,\n",
    "        drop_path_rate=config.drop_path_rate,\n",
    "        use_gem=config.use_gem,\n",
    "        head_3d=config.head_3d if hasattr(config, \"head_3d\") else \"\",\n",
    "        n_frames=config.n_frames if hasattr(config, \"n_frames\") else \"\",\n",
    "        replace_pad_conv=config.replace_pad_conv,\n",
    "        num_classes=config.num_classes,\n",
    "        num_classes_aux=config.num_classes_aux,\n",
    "        n_channels=config.n_channels,\n",
    "        reduce_stride=config.reduce_stride,\n",
    "        increase_stride=config.increase_stride if hasattr(config, \"increase_stride\") else False,\n",
    "        pretrained=False\n",
    "    )\n",
    "    model = model.cuda().eval()\n",
    "    \n",
    "    preds = []\n",
    "    for fold in folds:\n",
    "        weights = exp_folder + f\"{config.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "        \n",
    "        transfos = get_transfos(\n",
    "            augment=False, resize=config.resize, crop=config.crop\n",
    "        )\n",
    "\n",
    "        dataset = AbdominalCropDataset(\n",
    "            None,\n",
    "            None,\n",
    "            transforms=transfos,\n",
    "            frames_chanel=config.frames_chanel,\n",
    "            n_frames=config.n_frames,\n",
    "            stride=config.stride,\n",
    "            use_mask=config.use_mask,\n",
    "            train=False,\n",
    "            df_series=df_series\n",
    "        )\n",
    "\n",
    "        pred = predict(\n",
    "            model,\n",
    "            dataset,\n",
    "            config.loss_config,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.mean(preds, 0)\n",
    "    crop_fts.append(preds)\n",
    "    \n",
    "crop_fts = np.array(crop_fts) # n_models x 3*n_studies x n_classes\n",
    "np.save(SAVE_FOLDER + \"crop_fts.npy\", crop_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fts = np.load(SAVE_FOLDER + \"crop_fts.npy\")\n",
    "\n",
    "crop_fts = crop_fts.reshape(crop_fts.shape[0], crop_fts.shape[1] // 3, 3, crop_fts.shape[2])  # n_models x n_studies x n_organs x 3\n",
    "crop_fts = crop_fts.transpose(1, 2, 0, 3)  # n_studies x n_organs x n_models x 3\n",
    "crop_fts = crop_fts.reshape(crop_fts.shape[0], crop_fts.shape[1], crop_fts.shape[2] * crop_fts.shape[3])  # n_studies x n_organs x 3 * n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (crop_fts - np.array(\n",
    "#     [[[9.94628906e-01, 4.81796265e-03, 7.89165497e-04],\n",
    "#     [9.96582031e-01, 2.68936157e-03, 7.21931458e-04],\n",
    "#     [8.11035156e-01, 1.51489258e-01, 3.75366211e-02]],\n",
    "#     [[9.93652344e-01, 5.71060181e-03, 7.65800476e-04],\n",
    "#     [9.96582031e-01, 2.56729126e-03, 6.94274902e-04],\n",
    "#     [9.68750000e-01, 1.92565918e-02, 1.19247437e-02]]]\n",
    "# )).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for exp_folder in EXP_FOLDERS_2:\n",
    "    config_2 = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "\n",
    "    dataset = PatientFeatureInfDataset(\n",
    "        df['series'],\n",
    "        config_2.exp_folders,\n",
    "        crop_fts=crop_fts,\n",
    "        max_len=config_2.max_len,\n",
    "        restrict=config_2.restrict,\n",
    "        resize=config_2.resize,\n",
    "        save_folder=SAVE_FOLDER,\n",
    "        half=HALF,\n",
    "    )\n",
    "    \n",
    "    model = define_model_2(\n",
    "        config_2.name,\n",
    "        ft_dim=config_2.ft_dim,\n",
    "        layer_dim=config_2.layer_dim,\n",
    "        n_layers=config_2.n_layers,\n",
    "        dense_dim=config_2.dense_dim,\n",
    "        p=config_2.p,\n",
    "        use_msd=config_2.use_msd,\n",
    "        num_classes=config_2.num_classes,\n",
    "        num_classes_aux=config_2.num_classes_aux,\n",
    "        n_fts=config_2.n_fts,\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "\n",
    "    for fold in FOLDS_2:\n",
    "        weights = exp_folder + f\"{config_2.name}_{fold}.pt\"\n",
    "        model = load_model_weights(model, weights, verbose=config.local_rank == 0)\n",
    "    \n",
    "        preds = predict_2(\n",
    "            model,\n",
    "            dataset,\n",
    "            config_2.loss_config,\n",
    "            batch_size=BATCH_SIZE_2,\n",
    "            use_fp16=USE_FP16,\n",
    "            num_workers=NUM_WORKERS,\n",
    "        )\n",
    "        all_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(all_preds, 0).astype(np.float64)\n",
    "\n",
    "for i in range(preds.shape[1]):\n",
    "    df[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "dfg = df.drop(['series', 'path', 'frame', 'patient_id'], axis=1).groupby('patient').mean().reset_index()\n",
    "sub = to_sub_format(dfg)\n",
    "\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.read_csv(exp_folder + 'df_oof.csv')\n",
    "df_oof = df_oof[df_oof['patient_id'].isin(sub['patient_id'].values.astype(int))]\n",
    "\n",
    "df_oof = df_oof[[\"patient_id\", \"fold\"] + list(df_oof.columns[-11:])]\n",
    "df_oof.columns = [\"patient_id\", \"fold\", \"bowel_injury\", \"extravasation_injury\"] + list(sub.columns[-9:])\n",
    "df_oof[\"extravasation_healthy\"] = 1 - df_oof[\"extravasation_injury\"]\n",
    "df_oof[\"bowel_healthy\"] = 1 - df_oof[\"bowel_injury\"]\n",
    "\n",
    "df_oof = df_oof.sort_values('patient_id', ignore_index=True)\n",
    "\n",
    "df_oof['diff'] = (sub[sub.columns[1:]] - df_oof[sub.columns[1:]]).abs().max(1)\n",
    "\n",
    "df_oof = df_oof[list(sub.columns) + ['fold', 'diff']]\n",
    "# df_oof[df_oof['fold'] == FOLD]\n",
    "df_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv(SAVE_FOLDER + \"submission.csv\", index=False)\n",
    "# sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
