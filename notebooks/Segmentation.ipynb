{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.cuda.get_device_name(0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from data.dataset import *\n",
    "from data.preparation import *\n",
    "from data.transforms import get_transfos\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "from training.main_seg import k_fold\n",
    "\n",
    "from util.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df_img.groupby('series')[['patient_id', \"frame\"]].max().reset_index()\n",
    "\n",
    "segs = pd.DataFrame({\"path\": glob.glob(\"../input/segmentations/*.nii\")})\n",
    "segs['series'] = segs['path'].apply(lambda x: int(x.split('/')[-1][:-4]))\n",
    "segs = segs.merge(series)\n",
    "segs = segs[[\"patient_id\", \"series\", \"frame\", \"path\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "PLOT = True\n",
    "\n",
    "SAVE_FOLDER = \"../input/segs/\"\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cmap()\n",
    "\n",
    "for idx in tqdm(range(len(segs))):\n",
    "    patient_id = segs['patient_id'][idx]\n",
    "    series = segs['series'][idx]\n",
    "\n",
    "    imgs = sorted(glob.glob(\"../input/imgs/\" + f\"{patient_id}_{series}_*\"))\n",
    "    seg = load_segmentation(segs['path'][idx])\n",
    "    \n",
    "    ids = [i * len(imgs) // 5 for i in range(1, 5)]\n",
    "\n",
    "    if PLOT:\n",
    "        plt.figure(figsize=(20, 5))\n",
    "    for i, frame in enumerate(seg):\n",
    "        if SAVE:\n",
    "            cv2.imwrite(SAVE_FOLDER + f\"{patient_id}_{series}_{i:04d}.png\", frame)\n",
    "        \n",
    "        if i in ids and PLOT:\n",
    "            plt.subplot(1, len(ids), ids.index(i) + 1)\n",
    "            img = cv2.imread(imgs[i], cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            plot_mask(img, frame)\n",
    "            plt.title(f'Frame {i}')\n",
    "\n",
    "    if PLOT:\n",
    "        plt.show()\n",
    "#         if idx > 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_seg = pd.DataFrame({\"mask_path\": sorted(glob.glob('../input/segs/*.png'))})\n",
    "# df_seg['patient_id'] = df_seg['mask_path'].apply(lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "# df_seg['series'] = df_seg['mask_path'].apply(lambda x: int(x.split('/')[-1].split('_')[1]))\n",
    "# df_seg['frame'] = df_seg['mask_path'].apply(lambda x: int(x.split('/')[-1].split('_')[2][:-4]))\n",
    "\n",
    "# df_seg['img_path'] = df_seg['mask_path'].apply(lambda x: re.sub(\"/segs/\", \"/imgs/\", x))\n",
    "# df_seg = df_seg[[\"patient_id\", \"series\", \"frame\", \"img_path\", \"mask_path\"]]\n",
    "\n",
    "# df_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_counts = []\n",
    "# ph = np.zeros(6)\n",
    "\n",
    "# for i in tqdm(range(len(df_seg))):\n",
    "#     mask = cv2.imread(df_seg['mask_path'][i], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#     cts = np.zeros(6)\n",
    "#     counts = np.bincount(mask.flatten())\n",
    "#     cts[:len(counts)] = counts\n",
    "\n",
    "#     pixel_counts.append(cts)\n",
    "    \n",
    "# pixel_counts = np.array(pixel_counts)\n",
    "# for k in labels:\n",
    "#     df_seg[f'pixel_count_{labels[k]}'] = pixel_counts[:, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_seg.to_csv('../input/df_seg.csv', index=False)\n",
    "# print('-> Saved df to ', '../input/df_seg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = np.random.choice(df_seg[df_seg['pixel_count_bowel'] > 10000].index)\n",
    "\n",
    "# img = cv2.imread(df_seg['img_path'][i], cv2.IMREAD_GRAYSCALE)\n",
    "# mask = cv2.imread(df_seg['mask_path'][i], cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "# plt.imshow(img, cmap='gray')\n",
    "# plt.imshow(np.where(mask, mask, np.nan), cmap='Set3', alpha=0.3)        \n",
    "# plt.axis(False)\n",
    "# plt.title(f'Frame {i}')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_pad(img, size=384):\n",
    "    h, w = img.shape[-2:]\n",
    "    if h >= size:\n",
    "        margin = (h - size) // 2\n",
    "        img = img[..., margin : margin + size, :]\n",
    "    else:\n",
    "        new_img = np.zeros(list(img.shape[:-2]) + [size, img.shape[-1]])\n",
    "        margin = (size - h) // 2\n",
    "        new_img[..., margin: margin + h, :] = img\n",
    "        img = new_img\n",
    "    if w >= size:\n",
    "        margin = (w - size) // 2\n",
    "        img = img[..., margin : margin + size]\n",
    "    else:\n",
    "        new_img = np.zeros(list(img.shape[:-2]) + [size, size])\n",
    "        margin = (size - w) // 2\n",
    "        new_img[..., margin: margin + w] = img\n",
    "        img = new_img\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FOLDER = \"../input/3ds/\"\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "MAX_LEN = 600\n",
    "SIZE = 256\n",
    "\n",
    "SAVE = True\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cmap()\n",
    "\n",
    "for idx in tqdm(range(len(segs))):\n",
    "    patient_id = segs['patient_id'][idx]\n",
    "    series = segs['series'][idx]\n",
    "\n",
    "    imgs = sorted(glob.glob(\"../input/imgs/\" + f\"{patient_id}_{series}_*\"))\n",
    "    imgs = np.array([cv2.imread(f, 0) for f in imgs[-MAX_LEN:]])\n",
    "\n",
    "    imgs = center_crop_pad(imgs, 384)\n",
    "\n",
    "    imgs = F.interpolate(torch.from_numpy(imgs).unsqueeze(0).unsqueeze(0), size=(SIZE, SIZE, SIZE), mode=\"nearest\")[0][0]\n",
    "    imgs = imgs.numpy()\n",
    "    \n",
    "    seg = load_segmentation(segs['path'][idx])[-MAX_LEN:]\n",
    "    seg = center_crop_pad(seg, 384).copy()\n",
    "    seg = F.interpolate(torch.from_numpy(seg).unsqueeze(0).unsqueeze(0), size=(SIZE, SIZE, SIZE), mode=\"nearest\")[0][0]\n",
    "    seg = seg.numpy()\n",
    "    \n",
    "    if SAVE:\n",
    "        np.save(SAVE_FOLDER + \"imgs/\" + f\"{patient_id}_{series}.npy\", imgs)\n",
    "        np.save(SAVE_FOLDER + \"segs/\" + f\"{patient_id}_{series}.npy\", seg)\n",
    "    \n",
    "    if PLOT:\n",
    "        ids = [i * len(imgs) // 5 for i in range(1, 5)]\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for i, id_ in enumerate(ids):\n",
    "            plt.subplot(1, len(ids), i + 1)\n",
    "            plot_mask(imgs[id_], seg[id_])\n",
    "            plt.title(f'Frame {id_}')\n",
    "        plt.show()\n",
    "        \n",
    "        ids = [i * imgs.shape[1] // 5 for i in range(1, 5)]\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for i, id_ in enumerate(ids):\n",
    "            plt.subplot(1, len(ids), i + 1)\n",
    "            plot_mask(imgs[:, id_], seg[:, id_])\n",
    "            plt.title(f'Frame {id_}')\n",
    "        plt.show()\n",
    "        \n",
    "        ids = [i * imgs.shape[2] // 5 for i in range(1, 5)]\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for i, id_ in enumerate(ids):\n",
    "            plt.subplot(1, len(ids), i + 1)\n",
    "            plot_mask(imgs[:, :, id_], seg[:, :, id_])\n",
    "            plt.title(f'Frame {id_}')\n",
    "        plt.show()\n",
    "#         if idx > 10:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = pd.DataFrame({\n",
    "    \"mask_path\": sorted(glob.glob(f'{SAVE_FOLDER}/segs/*.npy'))\n",
    "})\n",
    "df_seg['patient_id'] = df_seg['mask_path'].apply(lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "df_seg['series'] = df_seg['mask_path'].apply(lambda x: int(x.split('/')[-1].split('_')[1][:-4]))\n",
    "\n",
    "df_seg['img_path'] = df_seg['mask_path'].apply(lambda x: re.sub(\"/segs/\", \"/imgs/\", x))\n",
    "df_seg = df_seg[[\"patient_id\", \"series\", \"img_path\", \"mask_path\"]]\n",
    "\n",
    "df_seg.to_csv('../input/df_seg_3d.csv', index=False)\n",
    "df_seg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = prepare_seg_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv(\"../input/folds_4.csv\")\n",
    "df_seg = df_seg.merge(folds, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = df_seg[df_seg['fold'] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = df_seg[df_seg[[c for c in df_seg.columns if \"norm\" in c]].max(1) > 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg = df_seg[\n",
    "    (df_seg[SEG_TARGETS] > 1000).max(1)\n",
    "].reset_index(drop=True)  # subsample for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df_seg['pixel_count_liver_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_seg = df_seg[(df_seg[SEG_TARGETS] > 0).max(1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(augment=False, resize=(384, 384), crop=True, strength=0)\n",
    "\n",
    "dataset = SegDataset(df_seg, transforms=transforms, for_classification=False, use_soft_target=True)\n",
    "\n",
    "dataset_cls = SegDataset(df_seg, transforms=transforms, for_classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i, idx in enumerate(np.random.choice(len(dataset), 5)):\n",
    "# for i, idx in enumerate(range(0, len(dataset), 10)):\n",
    "    img, mask, y = dataset[idx]\n",
    "    \n",
    "#     _, y_cls, _ = dataset_cls[idx]\n",
    "#     print(y, y_cls)\n",
    "\n",
    "    img_ = img.numpy()[1].squeeze()\n",
    "    mask_ = mask.numpy().squeeze()\n",
    "\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plot_mask(img_, mask_)\n",
    "#     plt.title(str(y.numpy().astype(int)))\n",
    "    plt.title(str(np.round(y.numpy(), 2)))\n",
    "    plt.axis(False)\n",
    "    break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_seg import define_model\n",
    "from util.torch import load_model_weights\n",
    "from training.losses import SegLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\n",
    "    \"Unet\",\n",
    "    \"tf_efficientnetv2_s\",\n",
    "    num_classes=5,\n",
    "    num_classes_aux=5,\n",
    "    n_channels=3,\n",
    "    use_cls=False,\n",
    "    increase_stride=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_weights(model, \"../logs/2023-09-21/23/tf_efficientnetv2_s_0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img.cuda().unsqueeze(0)  # .repeat(2, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred, pred = model(x)\n",
    "mask_pred.size(), pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = (mask_pred.sigmoid() > 0.5)\n",
    "# pred = torch.where(pred.amax(1) > 0, pred.int().argmax(1) + 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = mask_pred.argmax(1).cpu().numpy()[0].astype(int)\n",
    "# pred = torch.where(pred.amax(1) > 0, pred.int().argmax(1) + 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(msk.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(img_, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SegLoss({\"name\": \"ce\", \"name_aux\": \"bce\", \"aux_loss_weight\": 0., \"num_classes\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "p = F.one_hot(mask.long(), num_classes=6).float().transpose(2, 3).transpose(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "p = p * a - 2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(\n",
    "    mask_pred.cpu().float(),\n",
    "    pred.cpu(),\n",
    "    mask.unsqueeze(0),  # .repeat(2, 1, 1, 1),\n",
    "    y.unsqueeze(0),  # .repeat(2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(\n",
    "    p.cpu().float(),\n",
    "    pred.cpu(),\n",
    "    mask.unsqueeze(0),  # .repeat(2, 1, 1, 1),\n",
    "    y.unsqueeze(0),  # .repeat(2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Data\n",
    "    resize = (512, 512)\n",
    "    aug_strength = 3\n",
    "    for_classification = True\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0]  # , 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "    name = \"tf_efficientnetv2_s\"\n",
    "    pretrained_weights = None\n",
    "    \n",
    "    num_classes = 5\n",
    "    num_classes_aux = 0\n",
    "    drop_rate = 0\n",
    "    drop_path_rate = 0\n",
    "    n_channels = 3\n",
    "    reduce_stride = False\n",
    "    replace_pad_conv = False\n",
    "    use_gem = True\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"bce\",\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"sigmoid\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"patient\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "        \"ousm_k\": 0,  # todo ?\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 16,\n",
    "        \"val_bs\": 16,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 5e-4,\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.,\n",
    "        \"weight_decay\": 0.,\n",
    "    }\n",
    "\n",
    "    epochs = 1\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 100\n",
    "    \n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "    \n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None\n",
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds = k_fold(Config, df_seg, log_folder=log_folder, run=run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
