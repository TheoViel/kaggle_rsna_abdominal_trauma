{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.cuda.get_device_name(0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "#     init_neptune,\n",
    ")\n",
    "\n",
    "from params import *\n",
    "from data.dataset import *\n",
    "from data.preparation import *\n",
    "from util.metrics import rsna_loss\n",
    "from util.plots import plot_confusion_matrix\n",
    "from model_zoo.models_lvl2 import define_model\n",
    "from inference.extract_features import Config as ConfigInf\n",
    "from training.main_lvl2 import k_fold, retrieve_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    (\"../logs/2023-09-20/14/\", \"seg\"),\n",
    "    (\"../logs/2023-09-20/36/\", \"probas_2d\"),  # convnext-tiny best\n",
    "    (\"../logs/2023-10-02/41/\", \"crop\"),\n",
    "#     (\"../logs/2023-09-30/20/\", \"crop\"),\n",
    "]\n",
    "EXP_FOLDER = EXP_FOLDERS[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigInf(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df_patient.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df_img = df_img.merge(folds)\n",
    "    df_patient = df_patient.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatientFeatureDataset(\n",
    "    df_patient[df_patient['fold'] == 0],\n",
    "    df_img[df_img['fold'] == 0],\n",
    "    EXP_FOLDERS,\n",
    "#     max_len=600,\n",
    "#     resize=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, k in enumerate(dataset.fts.keys()):\n",
    "#     if k[0] == 10004:\n",
    "#         print(i, k)\n",
    "        \n",
    "# ft, y, y_aux = dataset[178]\n",
    "# ft.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     x = dataset[i][0]\n",
    "#     lens.append(len(x))\n",
    "# #     break\n",
    "\n",
    "# sns.histplot(lens)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     fts = dataset[i][0]\n",
    "#     x = fts.numpy()\n",
    "#     lens.append(len(x))\n",
    "    \n",
    "# #     start, end = detect_start_end(x)\n",
    "    \n",
    "#     if len(x) > 1000:\n",
    "# #         plt.subplot(1, 2, 1)\n",
    "#         plt.plot(x[:, :5])\n",
    "# #         plt.axvline(start, c=\"salmon\")\n",
    "# #         plt.axvline(end, c=\"salmon\")\n",
    "        \n",
    "# #         plt.subplot(1, 2, 2)\n",
    "# #         plt.plot(kept)\n",
    "#         plt.show()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\"rnn_att\", ft_dim=x['x'].shape[-1], layer_dim=512, n_layers=1, dense_dim=256, num_classes=11, num_classes_aux=0, n_fts=x['ft'].shape[-1] * x['ft'].shape[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x['x'].unsqueeze(0), x['ft'].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Handle variable sequence length more cleverly\n",
    "- Tweak CNN\n",
    "- Tweak fancier archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Data\n",
    "    exp_folders = [\n",
    "#         (\"../logs/2023-09-06/4/\", \"seg\"),  # v2-s\n",
    "#         (\"../logs/2023-09-19/10/\", \"seg\"),  # v2-rw-t stride+\n",
    "        (\"../logs/2023-09-20/14/\", \"seg\"),  # v2-rw-t stride+ 384\n",
    "#         (\"../logs/2023-09-25/26/\", \"seg\"),  # v2-rw-t stride+ 384 4 classes\n",
    "#         (\"../logs/2023-09-24/20/\", \"seg3d\"),  # resnet18d 3D\n",
    "        \n",
    "#         (\"../logs/2023-09-22/9/\", \"probas\"),  # v2m\n",
    "#         (\"../logs/2023-09-21/32/\", \"probas\"),  # v2m\n",
    "#         (\"../logs/2023-09-22/24/\", \"probas\"),  # convnext-nano\n",
    "#         (\"../logs/2023-09-25/22/\", \"probas\"),  # convnext-tiny \n",
    "#         (\"../logs/2023-09-25/15/\", \"probas\"),  # convnext-tiny \n",
    "#         (\"../logs/2023-09-26/8/\", \"probas_3d\"),  # convnext-tiny rnn 3fs5\n",
    "        (\"../logs/2023-09-27/20/\", \"probas_3d\"),  # convnext-tiny rnn 3fs3\n",
    "#         (\"../logs/2023-09-26/32/\", \"probas_3d\"),  # convnext-tiny rnn 2.5D\n",
    "        (\"../logs/2023-09-26/39/\", \"probas_3d\"),  # convnext-tiny rnn 2.5D 5fs5\n",
    "#         (\"../logs/2023-09-27/19/\", \"probas_3d\"),  # convnext-nano rnn 2.5D 5fs5\n",
    "\n",
    "#         (\"../logs/2023-09-25/37/\", \"probas_2d\"),  # convnext-tiny bs8\n",
    "        (\"../logs/2023-09-20/36/\", \"probas_2d\"),  # convnext-tiny best \n",
    "#         (\"../output/confs_rsna_v1_fold*_2\", \"yolox\"),\n",
    "    ]\n",
    "\n",
    "    restrict = True\n",
    "    max_len = 600 if restrict else 1000\n",
    "    resize = 200\n",
    "    n_fts = 0  # already pooled features, not supported yet\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "#     name = \"rnn\"\n",
    "    name = \"transfo\"\n",
    "    ft_dim = (11 + 11) * len([p for p in exp_folders if \"probas\" in p[1]]) + 5 # + 4\n",
    "\n",
    "    dense_dim = 256  # 384\n",
    "    layer_dim = 128\n",
    "    n_layers = 1\n",
    "\n",
    "    p = 0.1\n",
    "    use_msd = False\n",
    "    num_classes = 11\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"patient\",\n",
    "        \"weighted\": True,\n",
    "        \"use_any\": True,\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"patient\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"patient\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"val_bs\": 256,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"sched\": False,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 5e-4,  # 7e-4, 9e-4\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.,\n",
    "        \"weight_decay\": 0.2,\n",
    "    }\n",
    "\n",
    "    epochs = 8\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 50\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "\n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Data\n",
    "    exp_folders = [\n",
    "        (\"../logs/2023-09-20/14/\", \"seg\"),  # v2-rw-t stride+ 384\n",
    "#         (\"../logs/2023-09-24/20/\", \"seg3d\"),  # resnet18d 3D\n",
    "\n",
    "        (\"../logs/2023-09-20/36_r/\", \"probas_2d\"),  # 0.358 - convnext-tiny best  <-\n",
    "        (\"../logs/2023-09-27/20_r/\", \"probas_3d\"),  # 0.349 with 36_r - convnext-tiny rnn 3fs3  <-\n",
    "#         (\"../logs/2023-09-26/39_r/\", \"probas_3d\"),  # convnext-tiny rnn 2.5D 5fs5  <- REMOVE ?\n",
    "        \n",
    "#         (\"../logs/2023-09-25/39/\", \"probas_2d\"),  # 0.362 convnext-tiny bs8\n",
    "\n",
    "#         (\"../logs/2023-10-02/66/\", \"probas_2d\"),  # coat_lite_medium_384  \n",
    "#         (\"../logs/2023-10-02/66/\", \"probas_2d\"),  # coat_lite_medium_384  3s3f\n",
    "#         (\"../logs/2023-10-03/4/\", \"probas_2d\"),  # coat_lite_medium_384  bs+\n",
    "\n",
    "#         (\"../logs/2023-10-03/21/\",  \"probas_2d\"),  # convnext-tiny crop\n",
    "#         (\"../logs/2023-10-03/33/\",  \"probas_2d\"),  # convnext-tiny rerepro\n",
    "#         (\"../logs/2023-10-04/19/\", \"probas_2d\"),  # 0.359 convnext-tiny repro new - -0.001 resize longest / +0.002 crop \n",
    "#         (\"../logs/2023-10-04/20/\", \"probas_2d\"),  # convnext-tiny 512 new\n",
    "#         (\"../logs/2023-10-04/31/\", \"probas_2d\"),  # resize 512\n",
    "#         (\"../logs/2023-10-04/29/\", \"probas_2d\"),  # crop 448\n",
    "        \n",
    "        (\"../logs/2023-10-05/13/\", \"probas_2d\"),  # 0.353 - maxvit_tiny_tf_384   (+36_r - 0.347 / +20_ 0.342) <- \n",
    "#         (\"../logs/2023-10-05/14/\", \"probas_2d\")  # 0.414 coatnet_1_rw_224\n",
    "#         (\"../logs/2023-10-05/15/\", \"probas_2d\")  # 0.386 maxxvitv2_nano_rw_256\n",
    "#         (\"../logs/2023-10-05/23/\", \"probas_2d\")  # 0.384 maxxvitv2_rmlp_base_rw_384\n",
    "\n",
    "#         (\"../output/confs_rsna_v1_fold*_2\", \"yolox\"),\n",
    "        ### CROP MODELS with 3x convnext\n",
    "        # Convnext\n",
    "#         (\"../logs/2023-09-30/46/\", \"crop\"),  # -> 0.332 +\n",
    "#         (\"../logs/2023-10-03/1/\", \"crop\"),   # -> 0.332 +\n",
    "        \n",
    "        # CoAt\n",
    "#         (\"../logs/2023-10-02/11/\", \"crop\"),  # -> 0.328  <- \n",
    "#         (\"../logs/2023-10-02/36/\", \"crop\"),  # -> 0.329  <- \n",
    "#         (\"../logs/2023-10-02/41/\", \"crop\"),  # -> 0.327  <- \n",
    "#         (\"../logs/2023-10-02/51/\", \"crop\"),  # -> 0.329  <- \n",
    "#         (\"../logs/2023-10-02/70/\", \"crop\"),  # -> 0.328 5x5 (<-)\n",
    "        \n",
    "#         (\"../logs/2023-10-05/6/\", \"crop\"),  # -> 0.325\n",
    "#         (\"../logs/2023-10-05/8/\", \"crop\"),  # -> 0.328\n",
    "\n",
    "        \n",
    "        # Scores with 2x Convnext & maxvit\n",
    "        (\"../logs/2023-10-02/11/\", \"crop\"),  # -> 0.326\n",
    "        (\"../logs/2023-10-02/36/\", \"crop\"),   # -> 0.326\n",
    "        (\"../logs/2023-10-02/41/\", \"crop\"),  # -> 0.325\n",
    "#         (\"../logs/2023-10-02/51/\", \"crop\"),  # -> 0.327\n",
    "#         (\"../logs/2023-10-02/70/\", \"crop\")  # -> 0.326\n",
    "        (\"../logs/2023-10-05/6/\", \"crop\"),  # -> 0.322\n",
    "        (\"../logs/2023-10-05/8/\", \"crop\"),  # -> 0.326\n",
    "        (\"../logs/2023-10-05/20/\", \"crop\"),  # -> 0.325\n",
    "        (\"../logs/2023-10-05/21/\", \"crop\"),  # -> 0.325\n",
    "    ]\n",
    "\n",
    "    restrict = True\n",
    "    max_len = 600\n",
    "    resize = 200\n",
    "    n_fts = 9 * len([p for p in exp_folders if \"crop\" in p[1]])\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "#     name = \"rnn\"\n",
    "    name = \"rnn_att\"\n",
    "    ft_dim = (11 + 11) * len([p for p in exp_folders if \"probas\" in p[1]]) + 5 # + 4      # 11 + 8 ??\n",
    "    if any([\"yolox\" in mode for _, mode in exp_folders]):\n",
    "        ft_dim += 1\n",
    "\n",
    "    dense_dim = 384  # 384\n",
    "    layer_dim = 256\n",
    "    n_layers = 1\n",
    "\n",
    "    p = 0.\n",
    "    use_msd = False\n",
    "    num_classes = 11\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"patient\",\n",
    "        \"weighted\": True,\n",
    "        \"use_any\": True,\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"patient\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"patient\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"val_bs\": 256,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"sched\": False,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 4e-4,  # 4e-4, 5e-4\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.,\n",
    "        \"weight_decay\": 0.2,\n",
    "    }\n",
    "\n",
    "    epochs = 10\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 50\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "\n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not DEBUG:\n",
    "#     log_folder = prepare_log_folder(LOG_PATH)\n",
    "#     print(f\"Logging results to {log_folder}\")\n",
    "#     config_df = save_config(Config, log_folder + \"config.json\")\n",
    "#     create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "# preds, preds_aux = k_fold(Config, df_patient, df_img, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat ../logs/2023-10-02/26/config.json\n",
    "# !cat ../logs/2023-10-02/26/logs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "#     \"../logs/2023-09-21/27/\",  # 0.358 - rnn_att - convnext-tiny best 384 x seg 384       <--- best 2D\n",
    "#     \"../logs/2023-09-25/28/\",  # 0.361 - transfo - convnext-tiny best 384 x seg 384       <--- best 2D + transfo\n",
    "#     \"../logs/2023-09-25/17/\",  # 0.357 - rnn_att  - convnext-tiny best 384 x seg 384 + 3d  <--- best 2D + 3D\n",
    "\n",
    "#     # 3 frames + best 2D\n",
    "#     \"../logs/2023-09-26/36/\",  # 0.352 - rnn_att - convnext-tiny best 2D & RNN 3 frames   ---       8\n",
    "#     \"../logs/2023-09-26/37/\",  # 0.351 - rnn_att - convnext-tiny best 2D & RNN 3 frames   ---       8\n",
    "#     \"../logs/2023-09-26/38/\",  # 0.357 - transfo - convnext-tiny best 2D & RNN 3 frames   ---       8\n",
    "#     \"../logs/2023-09-27/16/\",  # 0.351 - rnn_att - convnext-tiny best 2D & RNN 3 frames   ---       8\n",
    "#     \"../logs/2023-09-27/2/\",   # 0.352 - rnn_att - convnext-tiny best 2D & RNN 3 frames   ---       32\n",
    "    \n",
    "#     # 5 frames + best 2D\n",
    "#     \"../logs/2023-09-27/11/\",   # 0.350 - rnn_att - convnext-tiny best 2D & RNN 5 frames   ---      39\n",
    "#     \"../logs/2023-09-27/13/\",   # 0.351 - rnn_att - convnext-tiny best 2D & RNN 5 frames   ---      40\n",
    "    \n",
    "#     # 5 frames + 3 frames + best 2D\n",
    "#     \"../logs/2023-09-27/10/\",   # 0.346 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames    ---     8 39\n",
    "#     \"../logs/2023-09-27/17/\",   # 0.348 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames    ---     8 40\n",
    "#     \"../logs/2023-09-27/14/\",   # 0.348 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames    ---     32 40\n",
    "#     \"../logs/2023-09-27/15/\",   # 0.347 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames    ---     32 39\n",
    " \n",
    "#     \"../logs/2023-09-27/28/\",   # 0.346 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames    ---     20 39\n",
    "#     \"../logs/2023-09-27/29/\",   # 0.346 - rnn_att - convnext-tiny best 2D & RNN 3 3 & 5 frames  ---   8 20 39\n",
    "#     \"../logs/2023-10-02/27/\",     # 0.344 - rnn_att p - convnext-tiny best 2D & RNN 3 & 5 frames  ---     20 39     <---   SUBMIT\n",
    "        \n",
    "#     \"../logs/2023-10-02/60/\",\n",
    "    \n",
    "#     \"../logs/2023-09-28/15/\",     # 0.359 - rnn_att p - convnext-tiny best 2D   ---\n",
    "        \n",
    "#     \"../logs/2023-09-27/31/\",   # 0.344 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & yolox   0     20 39 yoloX      0.343 r\n",
    "    \n",
    "\n",
    "#     \"../logs/2023-09-30/31/\",   # 0.334 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39\n",
    "    \n",
    "#     \"../logs/2023-10-01/28/\",   # 0.329 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 20 46 0\n",
    "#     \"../logs/2023-10-01/31/\",   # 0.329 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 20 46 0\n",
    "#     \"../logs/2023-10-01/39/\",   # 0.329 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 20 46 50 0\n",
    "#     \"../logs/2023-10-01/41/\"   # 0.329 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 20 29 46 50 0\n",
    "    \n",
    "#     \"../logs/2023-10-02/26/\",   # 0.326 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 46 11\n",
    "#     \"../logs/2023-10-02/25/\",   # 0.325 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 46 11 41\n",
    "#     \"../logs/2023-10-02/25/\",   # 0.324 - rnn_att - convnext-tiny best 2D & RNN 3 & 5 frames & crop   20 39 - 46 11 41 51 \n",
    "    \n",
    "#     \"../logs/2023-10-02/63/\",   # 0.326 - rnn_att - convnext-tiny best 2D & RNN 3 & crop   20 - 46 11 36 41 51\n",
    "#     \"../logs/2023-10-02/64/\",   # 0.325 - rnn_att - convnext-tiny best 2D & RNN 3 & crop   20 - 11 36 41 51\n",
    "#     \"../logs/2023-10-02/68/\",   # 0.327 - rnn_att - convnext-tiny best 2D & RNN 3 & crop   20 - 11 41\n",
    "#     \"../logs/2023-10-03/13/\",   # 0.325 - rnn_att - convnext-tiny best 2D & RNN 3 & crop   20 - 11 36 41 51 70\n",
    "\n",
    "#     \"../logs/2023-10-04/1/\"\n",
    "#     \"../logs/2023-10-03/22/\"  # 0.331 - 20 36 - 41                              <---  LB 0.38\n",
    "#     \"../logs/2023-10-05/11/\",   # 0.324 - rnn_att - 36_r 20_r - 11 36 41 51      \n",
    "#     \"../logs/2023-10-05/19/\",  # 0.322  -  rnn_att - 36_r 20_r - 11 36 41 51 6\n",
    "#     \"../logs/2023-10-05/19/\",  # 0.321  -  rnn_att - 36_r 20_r - 11 36 41 51 6 8\n",
    "#     \"../logs/2023-10-05/49/\",  # 0.319 - rnn_att - 36_r 20_r 13 - 41 6 20 21\n",
    "#     \"../logs/2023-10-05/53/\",  # 0.321 - rnn_att - 36_r 20_r  - 41 6 20 21\n",
    "    \"../logs/2023-10-05/54/\",  # 0.316 - rnn_att - 36_r 20_r 13 - 11 36 41 6 8 20 21    <---   BEST\n",
    "#     \"../logs/2023-10-05/55/\",  # 0.318 - rnn_att - 36_r 13 - 11 36 41 6 8 20 21\n",
    "#     \"../logs/2023-10-05/56/\",  # 0.316 - rnn_att - 36_r 20_r 13 - 11 36 41 51 70 6 8 20 21\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_oof = []\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    cfg = ConfigInf(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    print(\n",
    "        exp_folder, \" --> \",\n",
    "        \"proba :\",\n",
    "        \" - \".join(e[8:] for e, m in cfg.exp_folders if \"proba\" in m),\n",
    "        \"\\t crop : \",\n",
    "        \" - \".join(e[8:] for e, m in cfg.exp_folders if \"crop\" in m),\n",
    "    )\n",
    "\n",
    "    df_oof, pred_oof = retrieve_preds(\n",
    "        df_patient,\n",
    "        df_img,\n",
    "        cfg,\n",
    "        exp_folder,\n",
    "        custom_agg=False,\n",
    "#         folds=[0]\n",
    "    )\n",
    "    preds_oof.append(pred_oof)\n",
    "#     df_oof.to_csv(exp_folder + 'df_oof.csv', index=False)\n",
    "\n",
    "pred_oof = np.mean(preds_oof, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "\n",
    "print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check kaggle score\n",
    "\n",
    "# df_oof = df_oof.sort_values('patient_id').head(200)\n",
    "# pred_oof = df_oof[df_oof.columns[-11:]].values\n",
    "\n",
    "# losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "\n",
    "# for k, v in losses.items():\n",
    "#     print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "\n",
    "# print(f'\\n -> CV Score : {avg_loss :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inference.lvl2 import to_sub_format\n",
    "\n",
    "# preds = pred_oof.copy()\n",
    "# df = df_oof.copy()\n",
    "\n",
    "# for i in range(preds.shape[1]):\n",
    "#     df[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "# # dfg = df.drop(['series', 'path', 'frame', 'patient_id'], axis=1).groupby('patient').mean().reset_index()\n",
    "# sub = to_sub_format(df.rename(columns={\"patient_id\": \"patient\"}))\n",
    "# sub.to_csv(f'../output/submission_{int(avg_loss * 1000)}.csv', index=False)\n",
    "\n",
    "# print('-> Saved to', f'../output/submission_{int(avg_loss * 1000)}.csv')\n",
    "\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(22, 4))\n",
    "\n",
    "# plt.subplot(1, 5, 1)\n",
    "# plot_confusion_matrix(pred_oof[:, 0] > 0.5, df_oof[PATIENT_TARGETS[0]], display_labels=[\"ok\", \"injury\"], normalize=None, show_label=True)\n",
    "# plt.title(PATIENT_TARGETS[0])\n",
    "\n",
    "# plt.subplot(1, 5, 2)\n",
    "# plot_confusion_matrix(pred_oof[:, 1] > 0.5, df_oof[PATIENT_TARGETS[1]], display_labels=[\"ok\", \"injury\"], normalize=None)\n",
    "# plt.title(PATIENT_TARGETS[1])\n",
    "\n",
    "# plt.subplot(1, 5, 3)\n",
    "# plot_confusion_matrix(pred_oof[:, 2:5].argmax(-1), df_oof[PATIENT_TARGETS[2]], display_labels=[\"ok\", \"low\", \"high\"], normalize=None)\n",
    "# plt.title(PATIENT_TARGETS[2])\n",
    "\n",
    "# plt.subplot(1, 5, 4)\n",
    "# plot_confusion_matrix(pred_oof[:, 5:8].argmax(-1), df_oof[PATIENT_TARGETS[3]], display_labels=[\"ok\", \"low\", \"high\"], normalize=None)\n",
    "# plt.title(PATIENT_TARGETS[3])\n",
    "\n",
    "# plt.subplot(1, 5, 5)\n",
    "# plot_confusion_matrix(pred_oof[:, 9:].argmax(-1), df_oof[PATIENT_TARGETS[4]], display_labels=[\"ok\", \"low\", \"high\"], normalize=None)\n",
    "# plt.title(PATIENT_TARGETS[4])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.preparation import get_df_series\n",
    "\n",
    "# dfs = []\n",
    "# for i in tqdm(range(4)):\n",
    "#     preds = np.load(f'../logs/2023-09-30/20/pred_val_{i}.npy')\n",
    "#     df_series = get_df_series(df_patient[df_patient['fold'] == i], df_img[df_img['fold'] == i])\n",
    "    \n",
    "#     cs = ['pred_healthy', 'pred_low', 'pred_high']\n",
    "#     for i, c in enumerate(cs):\n",
    "#         df_series[c] = preds[:, i]\n",
    "    \n",
    "#     df_series = df_series.groupby([\"patient_id\", \"series\"]).agg(list).reset_index()\n",
    "    \n",
    "#     i = 2\n",
    "#     for idx, c in enumerate([\"kidney\", \"liver\", \"spleen\"]):\n",
    "#         for p in ['pred_healthy', 'pred_low', 'pred_high']:\n",
    "#             df_series[f\"pred_{i}\"] = np.array(df_series[p].values.tolist())[:, idx]\n",
    "#             i += 1\n",
    "\n",
    "#     df_series = df_series[[\"patient_id\"] + [f\"pred_{i}\" for i in range(2, 11)]]\n",
    "#     df = df_series.groupby(\"patient_id\").mean().reset_index()\n",
    "#     dfs.append(df)\n",
    "    \n",
    "# df_crop = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_oof_c = df_oof.merge(df_crop, on=\"patient_id\")\n",
    "\n",
    "# pred_oof_1 = df_oof_c[[\"pred_0\", \"pred_1\"] + [f\"pred_{i}_x\" for i in range(2, 11)]].values\n",
    "# pred_oof_2 = df_oof_c[[\"pred_0\", \"pred_1\"] + [f\"pred_{i}_y\" for i in range(2, 11)]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, c in enumerate(['bowel_injury', 'extravasation_injury', 'kidney_healthy', 'kidney_low', 'kidney_high', 'liver_healthy', 'liver_low', 'liver_high', 'spleen_healthy', 'spleen_low', 'spleen_high']):\n",
    "#     if i > 1:\n",
    "#         auc_1 = roc_auc_score(df_oof[c], pred_oof_1[:, i])\n",
    "#         auc_2 = roc_auc_score(df_oof[c], pred_oof_2[:, i])\n",
    "#         print(f\"{c[:10]} AUC:\\t {auc_1 :.3f} - {auc_2 :.3f}  ({'+' if auc_2 > auc_1 else ''}{auc_2 - auc_1 :.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_preds = []\n",
    "df_oofs = []\n",
    "\n",
    "print(\"Exp folders :\\t\", \"\\t\".join(EXP_FOLDERS))\n",
    "\n",
    "for fold in [0, 1, 2, 3, \"fullfit\"]:\n",
    "    print(f'\\n ->  Fold {fold}')\n",
    "    train_folds = [f for f in range(4) if f != fold] \n",
    "    \n",
    "    preds_oof = []\n",
    "    for exp_folder in EXP_FOLDERS:\n",
    "        df_oof, pred_oof = retrieve_preds(df_patient, df_img, Config, exp_folder, folds=train_folds)\n",
    "        preds_oof.append(pred_oof)\n",
    "    pred_oof = np.mean(preds_oof, 0)\n",
    "\n",
    "    losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "    print(f'\\n- Train Score : {avg_loss :.3f}')\n",
    "    \n",
    "    print(f'\\n- Optimize coeffs on folds {train_folds}:\\n')\n",
    "    pred_oof_ = pred_oof.copy()\n",
    "    best_score = avg_loss\n",
    "    factors = {i: [1, 0] for i in range(pred_oof.shape[1])}\n",
    "    for _ in range(2):\n",
    "\n",
    "        for i in range(pred_oof.shape[1]):\n",
    "            scores = {}\n",
    "            for factor in np.round(np.arange(0.5, 1.5, 0.1), 2):\n",
    "                for shift in np.round(np.arange(-0.1, 0.11, 0.1), 2):\n",
    "    #             for shift in [-0.1, 0, 0.1]:\n",
    "                    pred_oof_r = pred_oof_.copy()\n",
    "                    pred_oof_r[:, i] = pred_oof_r[:, i] * factor + shift\n",
    "                    pred_oof_r[:, i] = np.clip(pred_oof_r[:, i], 0.00001, 0.99999)\n",
    "\n",
    "                    losses, avg_loss = rsna_loss(pred_oof_r, df_oof)\n",
    "                    scores[(factor, shift)] = avg_loss\n",
    "\n",
    "        #     print(scores)\n",
    "            best_coefs, best_loss = min(scores.items(), key=operator.itemgetter(1))\n",
    "            delta = best_score - best_loss \n",
    "            if delta > 0.0001:\n",
    "                pred_oof_[:, i] = np.clip(pred_oof_[:, i] * best_coefs[0] + best_coefs[1], 0.00001, 0.99999)\n",
    "                best_score = best_loss\n",
    "                print(f'{i} - {best_coefs}  -  {best_loss :.3f}  (-{delta:.4f})')\n",
    "                factors[i][0] = np.round(best_coefs[0] * factors[i][0], 2)\n",
    "                factors[i][1] += best_coefs[1]\n",
    "                \n",
    "    if fold != \"fullfit\":\n",
    "        # Validate\n",
    "        preds_oof = []\n",
    "        for exp_folder in EXP_FOLDERS:\n",
    "            df_oof, pred_oof = retrieve_preds(df_patient, df_img, Config, exp_folder, folds=[fold])\n",
    "            preds_oof.append(pred_oof)\n",
    "\n",
    "        pred_oof = np.mean(preds_oof, 0)\n",
    "\n",
    "        losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "        print(f'\\n- Val Score : {avg_loss :.3f}')\n",
    "\n",
    "        pred_oof_ = pred_oof.copy()\n",
    "        for i in range(pred_oof.shape[1]):\n",
    "            pred_oof_[:, i] *= factors[i][0]\n",
    "            pred_oof_[:, i] += factors[i][1]\n",
    "            pred_oof_[:, i] = np.clip(pred_oof_[:, i], 0.00001, 0.99999)\n",
    "\n",
    "        losses, avg_loss = rsna_loss(pred_oof_, df_oof)\n",
    "        print(f'- Rescaled val Score : {avg_loss :.3f}')\n",
    "\n",
    "        rescaled_preds.append(pred_oof_)\n",
    "        df_oofs.append(df_oof)\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses, avg_loss = rsna_loss(np.concatenate(rescaled_preds), pd.concat(df_oofs))\n",
    "\n",
    "# for k, v in losses.items():\n",
    "#     print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "    \n",
    "# print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inference.lvl2 import to_sub_format\n",
    "\n",
    "# preds = np.concatenate(rescaled_preds).astype(np.float64)\n",
    "# df = pd.concat(df_oofs)\n",
    "\n",
    "# for i in range(preds.shape[1]):\n",
    "#     df[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "# # dfg = df.drop(['series', 'path', 'frame', 'patient_id'], axis=1).groupby('patient').mean().reset_index()\n",
    "# sub = to_sub_format(df.rename(columns={\"patient_id\": \"patient\"}))\n",
    "# sub.to_csv(f'../output/submission_{int(avg_loss * 1000)}.csv', index=False)\n",
    "\n",
    "# print('-> Saved to', f'../output/submission_{int(avg_loss * 1000)}.csv')\n",
    "\n",
    "# sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
