{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.cuda.get_device_name(0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import operator\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "#     init_neptune,\n",
    ")\n",
    "\n",
    "from params import *\n",
    "from data.dataset import *\n",
    "from data.preparation import *\n",
    "from util.metrics import rsna_loss\n",
    "from model_zoo.models_lvl2 import define_model\n",
    "\n",
    "from training.main_lvl2 import k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient, df_img = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    \"../logs/2023-08-27/3/\",  # v2-s\n",
    "]\n",
    "EXP_FOLDER = EXP_FOLDERS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.extract_features import Config\n",
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", \"r\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fold\" not in df_patient.columns:\n",
    "    folds = pd.read_csv(config.folds_file)\n",
    "    df_img = df_img.merge(folds)\n",
    "    df_patient = df_patient.merge(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatientFeatureDataset(df_patient[df_patient['fold'] == 0], df_img[df_img['fold'] == 0], EXP_FOLDERS, max_len=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fts, y, _ = dataset[0]\n",
    "# fts.size(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = []\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     x = dataset[i][0]\n",
    "#     lens.append(len(x))\n",
    "    \n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\"rnn\", ft_dim=1280, layer_dim=128, dense_dim=256, num_classes=11, num_classes_aux=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.cat([fts.unsqueeze(0)] * 2)\n",
    "\n",
    "# pred, pred_aux = model(x)\n",
    "# pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- dynamic batch trimming ?\n",
    "- SWA\n",
    "- Transformer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Data\n",
    "    exp_folders = [\n",
    "#         \"../logs/2023-09-06/0/\",  # v2-s\n",
    "        \"../logs/2023-08-27/3/\",  # v2-s fix sampling\n",
    "    ]\n",
    "    max_len = 1000\n",
    "    n_fts = 0  # already pooled features, not supported yet\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = f\"../input/folds_{k}.csv\"\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "\n",
    "    # Model\n",
    "    name = \"rnn\"\n",
    "    ft_dim = 1280\n",
    "\n",
    "    layer_dim = 256\n",
    "    dense_dim = 256\n",
    "\n",
    "    p = 0.\n",
    "    use_msd = False\n",
    "    num_classes = 11\n",
    "    num_classes_aux = 0\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"patient\",\n",
    "        \"smoothing\": 0,\n",
    "        \"activation\": \"patient\",\n",
    "        \"aux_loss_weight\": 0,\n",
    "        \"name_aux\": \"patient\",\n",
    "        \"smoothing_aux\": 0,\n",
    "        \"activation_aux\": \"\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 64,\n",
    "        \"val_bs\": 256,\n",
    "        \"mix\": \"mixup\",\n",
    "        \"mix_proba\": 0.,\n",
    "        \"mix_alpha\": 4.,\n",
    "        \"additive_mix\": False,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"num_workers\": 8,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 3e-4,\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.,\n",
    "        \"weight_decay\": 0.,\n",
    "    }\n",
    "\n",
    "    epochs = 10\n",
    "\n",
    "    use_fp16 = True\n",
    "    verbose = 1\n",
    "    verbose_eval = 50\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n",
    "    \n",
    "    local_rank = 0\n",
    "    distributed = False\n",
    "    world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "preds, preds_aux = k_fold(Config, df_patient, df_img, log_folder=log_folder, run=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FOLDER = \"../logs/2023-09-04/2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for fold in tqdm(config.selected_folds):\n",
    "\n",
    "    df_val = df_patient[df_patient['fold'] == fold]\n",
    "    \n",
    "    dataset = PatientFeatureDataset(df_val, df_img[df_img['fold'] == fold], config.exp_folders)\n",
    "    patients = [d[0] for d in dataset.ids]\n",
    "    df_preds = pd.DataFrame({\"patient_id\": patients})\n",
    "    \n",
    "    preds = np.load(LOG_FOLDER + f\"pred_val_{fold}.npy\")\n",
    "\n",
    "    preds_cols = []\n",
    "    for i in range(preds.shape[1]):\n",
    "        preds_cols.append(f'pred_{i}')\n",
    "        df_preds[f'pred_{i}'] = preds[:, i]\n",
    "\n",
    "    df_preds = df_preds.groupby('patient_id').mean()\n",
    "    df = df_val.merge(df_preds, on=\"patient_id\")\n",
    "\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.concat(dfs, ignore_index=True)\n",
    "pred_oof = df_oof[preds_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "    \n",
    "print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'bowel_injury': 0, 'extravasation_injury': 1, 'kidney': 2, 'liver': 5, 'spleen': 8}\n",
    "for tgt in PATIENT_TARGETS:\n",
    "    if \"injury\" in tgt:\n",
    "        auc = roc_auc_score(df_oof[tgt] > 0, pred_oof[:, mapping[tgt]])\n",
    "    else:\n",
    "        auc = roc_auc_score(df_oof[tgt] <= 0, pred_oof[:, mapping[tgt]])\n",
    "        \n",
    "    print(f'- {tgt} auc : {auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof_ = pred_oof.copy()\n",
    "losses, avg_loss = rsna_loss(pred_oof, df_oof)\n",
    "best_score = avg_loss\n",
    "\n",
    "for _ in range(2):\n",
    "    factors = []\n",
    "    for i in range(pred_oof.shape[1]):\n",
    "        scores = {}\n",
    "        for factor in np.round(np.arange(0.5, 1.5, 0.1), 2):\n",
    "            for shift in np.round(np.arange(-0.1, 0.11, 0.1), 2):\n",
    "#             for shift in [-0.1, 0, 0.1]:\n",
    "                pred_oof_r = pred_oof_.copy()\n",
    "                pred_oof_r[:, i] = pred_oof_r[:, i] * factor + shift\n",
    "                pred_oof_r[:, i] = np.clip(pred_oof_r[:, i], 0.00001, 0.99999)\n",
    "\n",
    "                losses, avg_loss = rsna_loss(pred_oof_r, df_oof)\n",
    "                scores[(factor, shift)] = avg_loss\n",
    "\n",
    "    #     print(scores)\n",
    "        best_coefs, best_loss = min(scores.items(), key=operator.itemgetter(1))\n",
    "        pred_oof_[:, i] = pred_oof_[:, i] * best_coefs[0] + best_coefs[1]\n",
    "        best_score = best_loss\n",
    "        print(f'{i} - {best_coefs}  -  {best_loss :.3f}')\n",
    "        factors.append(best_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, avg_loss = rsna_loss(pred_oof_, df_oof)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "    \n",
    "print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.array(\n",
    "    [\n",
    "        [0.04] * len(df_oof), [0.3] * len(df_oof),\n",
    "        [0.6] * len(df_oof), [0.05] * len(df_oof), [0.05] * len(df_oof),\n",
    "        [0.4] * len(df_oof), [0.07] * len(df_oof), [0.03] * len(df_oof),\n",
    "        [0.3] * len(df_oof), [0.04] * len(df_oof), [0.07] * len(df_oof),\n",
    "    ]\n",
    ").T\n",
    "losses, avg_loss = rsna_loss(dummy, df_oof)\n",
    "\n",
    "for k, v in losses.items():\n",
    "    print(f\"- {k.split('_')[0][:8]} loss\\t: {v:.3f}\")\n",
    "    \n",
    "print(f'\\n -> CV Score : {avg_loss :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     sns.histplot(preds[:, i])\n",
    "    \n",
    "#     auc = roc_auc_score(df_val[PATIENT_TARGETS[i]], preds[:, i])\n",
    "#     print(f'- {PATIENT_TARGETS[i]} auc : {auc:.3f}')\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
